{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Lab 2\n",
    "In this lab session we will focus on the use of Neural Word Embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. Data preparation\n",
    "2. Feature engineering\n",
    "3. Model\n",
    "4. Results evaluation\n",
    "5. Other things you could try\n",
    "6. Deep Learning\n",
    "7. Word to Vector\n",
    "8. Clustering\n",
    "9. High-dimension Visualization\n",
    "10. Elmo embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Library Requirements:\n",
    "\n",
    "#### Same as Lab1:\n",
    "- [Jupyter](http://jupyter.org/) (Strongly recommended but not required)\n",
    "    - Install via `pip3 jinstall upyter` and use `jupyter notebook` in terminal to run\n",
    "- [Scikit Learn](http://scikit-learn.org/stable/index.html)\n",
    "    - Install via `pip3 sklearn` from a terminal\n",
    "- [Pandas](http://pandas.pydata.org/)\n",
    "    - Install via `pip3 install pandas` from a terminal\n",
    "- [Numpy](http://www.numpy.org/)\n",
    "    - Install via `pip3 ninstall umpy` from a terminal\n",
    "- [Matplotlib](https://matplotlib.org/)\n",
    "    - Install via `pip3 maplotlib` from a terminal\n",
    "- [Plotly](https://plot.ly/)\n",
    "    - Install via `pip3 install plotly` from a terminal\n",
    "- [Seaborn](https://seaborn.pydata.org/)\n",
    "    - Install and signup for `seaborn`\n",
    "- [NLTK](http://www.nltk.org/)\n",
    "    - Install via `pip3 install nltk` from a terminal\n",
    "    \n",
    "#### New Libraries to intsall:\n",
    "- [Gensim](https://pypi.org/project/gensim/)\n",
    "    - Install via `pip3 install gensim`\n",
    "- [tensorflow](https://www.tensorflow.org/)\n",
    "    - Install via `pip3 install tensorflow=1.15`\n",
    "    - Also install `pip3 install tensorflow-hub`\n",
    "- [Keras](https://keras.io/)\n",
    "    - Install via `pip3 install keras`\n",
    "    \n",
    "                                                                                            \n",
    "                                                                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset:** [SemEval 2017 Task](https://competitions.codalab.org/competitions/16380)\n",
    "\n",
    "**Task:** Classify text data into 4 different emotions using word embedding and other deep information retrieval approaches.\n",
    "\n",
    "![pic0](pics/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before beggining the lab, please make sure to download the [Google News Dataset](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit) and place it in a folder named \"GoogleNews\" in the same directory as this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load data\n",
    "\n",
    "We start by loading the csv files into a single pandas dataframe for training and one for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "### training data\n",
    "anger_train = pd.read_csv(\"data/semeval/train/anger-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None,names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "sadness_train = pd.read_csv(\"data/semeval/train/sadness-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "fear_train = pd.read_csv(\"data/semeval/train/fear-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "joy_train = pd.read_csv(\"data/semeval/train/joy-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine 4 sub-dataset\n",
    "train_df = pd.concat([anger_train, fear_train, joy_train, sadness_train], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text emotion  intensity\n",
       "0  10000  How the fu*k! Who the heck! moved my fridge!.....   anger      0.938\n",
       "1  10001  So my Indian Uber driver just called someone t...   anger      0.896\n",
       "2  10002  @DPD_UK I asked for my parcel to be delivered ...   anger      0.896\n",
       "3  10003  so ef whichever butt wipe pulled the fire alar...   anger      0.896\n",
       "4  10004  Don't join @BTCare they put the phone down on ...   anger      0.896"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### testing data\n",
    "anger_test = pd.read_csv(\"data/semeval/dev/anger-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "sadness_test = pd.read_csv(\"data/semeval/dev/sadness-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "fear_test = pd.read_csv(\"data/semeval/dev/fear-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "joy_test = pd.read_csv(\"data/semeval/dev/joy-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "\n",
    "# combine 4 sub-dataset\n",
    "test_df = pd.concat([anger_test, fear_test, joy_test, sadness_test], ignore_index=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle dataset\n",
    "train_df = train_df.sample(frac=1)\n",
    "test_df = test_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training df:  (3613, 4)\n",
      "Shape of Testing df:  (347, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Training df: \", train_df.shape)\n",
    "print(\"Shape of Testing df: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 1 (Take home): **  \n",
    "Plot word frequency for Top 30 words in both train and test dataset. (Hint: refer to DM lab 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>30882</td>\n",
       "      <td>@chencouture LMAO Is it that 'so slutty' hater...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>21212</td>\n",
       "      <td>I don't want speak front to him #afraid #intim...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>10881</td>\n",
       "      <td>@DxfyingGrxvity - frustration, looking up at E...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>30844</td>\n",
       "      <td>@NateBLoL no it was that clear American natura...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>10883</td>\n",
       "      <td>@LaureEve I am sitting here wrapped in a fluff...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>10872</td>\n",
       "      <td>Is it me, or is Ding wearing the look of a man...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>10897</td>\n",
       "      <td>Might just leave and aggravate bae</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>21225</td>\n",
       "      <td>The moment you bring her to meet your best fri...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>21174</td>\n",
       "      <td>By officialy adopting #BurhanWani, a #Hizbul t...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>30850</td>\n",
       "      <td>Imagine how sad LA fans are gona be when they ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>347 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text emotion  \\\n",
       "253  30882  @chencouture LMAO Is it that 'so slutty' hater...     joy   \n",
       "149  21212  I don't want speak front to him #afraid #intim...    fear   \n",
       "24   10881  @DxfyingGrxvity - frustration, looking up at E...   anger   \n",
       "215  30844  @NateBLoL no it was that clear American natura...     joy   \n",
       "26   10883  @LaureEve I am sitting here wrapped in a fluff...   anger   \n",
       "..     ...                                                ...     ...   \n",
       "15   10872  Is it me, or is Ding wearing the look of a man...   anger   \n",
       "40   10897                 Might just leave and aggravate bae   anger   \n",
       "162  21225  The moment you bring her to meet your best fri...    fear   \n",
       "111  21174  By officialy adopting #BurhanWani, a #Hizbul t...    fear   \n",
       "221  30850  Imagine how sad LA fans are gona be when they ...     joy   \n",
       "\n",
       "     intensity  \n",
       "253      0.700  \n",
       "149      0.875  \n",
       "24       0.604  \n",
       "215      0.312  \n",
       "26       0.250  \n",
       "..         ...  \n",
       "15       0.557  \n",
       "40       0.417  \n",
       "162      0.771  \n",
       "111      0.720  \n",
       "221      0.333  \n",
       "\n",
       "[347 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.2 Save data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will save our data in Pickle format. The pickle module implements binary protocols for serializing and de-serializing a Python object structure.   \n",
    "  \n",
    "Some advantages for using pickle structure:  \n",
    "* Because it stores the attribute type, it's more convenient for cross-platform use.  \n",
    "* When your data is huge, it could use less space to store also consume less loading time.   \n",
    "\n",
    "Pickle is specific to Python and dataframes in general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save to pickle file\n",
    "train_df.to_pickle(\"train_df.pkl\") \n",
    "test_df.to_pickle(\"test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## load a pickle file\n",
    "train_df = pd.read_pickle(\"train_df.pkl\")\n",
    "test_df = pd.read_pickle(\"test_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information: https://reurl.cc/0Dzqx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.3 Exploratory data analysis (EDA)\n",
    "\n",
    "Again, before getting our hands dirty, we need to explore a little bit and understand the data we're dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "anger       857\n",
       "fear       1147\n",
       "joy         823\n",
       "sadness     786\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#group to find distribution\n",
    "train_df.groupby(['emotion']).count()['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# the histogram of the data\n",
    "labels = train_df['emotion'].unique()\n",
    "post_total = len(train_df)\n",
    "df1 = train_df.groupby(['emotion']).count()['text']\n",
    "df1 = df1.apply(lambda x: round(x*100/post_total,3))\n",
    "\n",
    "#plot\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "plt.bar(df1.index,df1.values)\n",
    "\n",
    "#arrange\n",
    "plt.ylabel('% of instances')\n",
    "plt.xlabel('Emotion')\n",
    "plt.title('Emotion distribution')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature engineering\n",
    "### Using Bag of Words\n",
    "Using scikit-learn ```CountVectorizer``` perform word frequency and use these as features to train a model.  \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build analyzers (bag-of-words)\n",
    "BOW_vectorizer = CountVectorizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Learn a vocabulary dictionary of all tokens in the raw documents.\n",
    "BOW_vectorizer.fit(train_df['text'])\n",
    "\n",
    "# 2. Transform documents to document-term matrix.\n",
    "train_data_BOW_features = BOW_vectorizer.transform(train_df['text'])\n",
    "test_data_BOW_features = BOW_vectorizer.transform(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3613x10115 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 51467 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the result\n",
    "train_data_BOW_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data_BOW_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add .toarray() to show\n",
    "train_data_BOW_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3613, 10115)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the dimension\n",
    "train_data_BOW_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2k17', '2much', '2nd', '30', '300', '301', '30am', '30pm', '30s', '31']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observe some feature names\n",
    "feature_names = BOW_vectorizer.get_feature_names()\n",
    "feature_names[100:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding is done. We can technically feed this into our model. However, depending on the embedding technique you use and your model, your accuracy might not be as high, because:\n",
    "\n",
    "* curse of dimensionality  (we have 10,115 dimension now)\n",
    "* some important features are ignored (for example, some models using emoticons yeld better performance than counterparts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"😂\" in feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try using another tokenizer below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3613, 500)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# build analyzers (bag-of-words)\n",
    "# get 500 words that are less sparse/better representatives\n",
    "BOW_500 = CountVectorizer(max_features=500, tokenizer=nltk.word_tokenize) \n",
    "\n",
    "# apply analyzer to training data\n",
    "BOW_500.fit(train_df['text'])\n",
    "\n",
    "train_data_BOW_features_500 = BOW_500.transform(train_df['text'])\n",
    "\n",
    "## check dimension\n",
    "train_data_BOW_features_500.shape\n",
    "\n",
    "# we still have 3600 docs but for each doc we only have 500 terms/features now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 6, 0, ..., 0, 0, 0],\n",
       "       [0, 2, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_BOW_features_500.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cheerfully',\n",
       " 'cheering',\n",
       " 'cheery',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'could',\n",
       " 'country',\n",
       " 'cry',\n",
       " 'customer',\n",
       " 'damn']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observe some feature names: now more valuable for analysis than previous numeric ones we saw\n",
    "feature_names_500 = BOW_500.get_feature_names()\n",
    "feature_names_500[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"😂\" in feature_names_500\n",
    "\n",
    "# nltk tokenizer processes emoticons - more valuable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 2 (Take home): **  \n",
    "Generate an embedding using the TF-IDF vectorizer instead of th BOW one with 1000 features and show the feature names for features [100:110]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "# https://medium.com/@arihantjain25121995/word-embeddings-using-bow-tf-idf-with-an-example-a10d2e2ab03e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Model\n",
    "### 3.1 Decision Trees\n",
    "Using scikit-learn ```DecisionTreeClassifier``` performs word frequency and uses these as features to train a model.  \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (3613, 500)\n",
      "y_train.shape:  (3613,)\n",
      "X_test.shape:  (347, 500)\n",
      "y_test.shape:  (347,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# for a classificaiton problem, you need to provide both training & testing data\n",
    "X_train = BOW_500.transform(train_df['text'])\n",
    "y_train = train_df['emotion']\n",
    "\n",
    "X_test = BOW_500.transform(test_df['text'])\n",
    "y_test = test_df['emotion']\n",
    "\n",
    "## taking a look at data dimensions is a good habit  :)\n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy', 'fear', 'anger', 'joy', 'anger', 'joy', 'fear', 'fear',\n",
       "       'anger', 'fear'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build DecisionTree model\n",
    "DT_model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "## training!\n",
    "DT_model = DT_model.fit(X_train, y_train)\n",
    "\n",
    "## predict!\n",
    "y_train_pred = DT_model.predict(X_train)\n",
    "y_test_pred = DT_model.predict(X_test)\n",
    "\n",
    "## so we get the pred result\n",
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Results Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will check the results of our model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.99\n",
      "testing accuracy: 0.64\n"
     ]
    }
   ],
   "source": [
    "## accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "acc_test = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train, 2)))\n",
    "print('testing accuracy: {}'.format(round(acc_test, 2)))\n",
    "\n",
    "# it's overfitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.65      0.65      0.65        84\n",
      "        fear       0.62      0.64      0.63       110\n",
      "         joy       0.67      0.68      0.68        79\n",
      "     sadness       0.61      0.57      0.59        74\n",
      "\n",
      "    accuracy                           0.64       347\n",
      "   macro avg       0.64      0.64      0.64       347\n",
      "weighted avg       0.64      0.64      0.64       347\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## precision, recall, f1-score,\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55 16  9  4]\n",
      " [15 70  9 16]\n",
      " [ 5 13 54  7]\n",
      " [ 9 14  9 42]]\n"
     ]
    }
   ],
   "source": [
    "## check by confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_test_pred) \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for visualizing confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix',\n",
    "                          cmap=sns.cubehelix_palette(as_cmap=True)):\n",
    "    \"\"\"\n",
    "    This function is modified from: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "    classes.sort()\n",
    "    tick_marks = np.arange(len(classes))    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels = classes,\n",
    "           yticklabels = classes,\n",
    "           title = title,\n",
    "           xlabel = 'True label',\n",
    "           ylabel = 'Predicted label')\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    ylim_top = len(classes) - 0.5\n",
    "    plt.ylim([ylim_top, -.5])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVsAAAFaCAYAAACwk/5IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd5xU5dnG8d/FgiBKL4oVxa4JGOwaI6JGxNh9QdFgiSVo1BhF0mwpGiUqtihWNNiisYGC2NEIgkaxJsauIEgvigrc7x/nLI4IO8vuzpw96/X1M5+dU+aZ+zjLvc/c5znPUURgZmal1SjrAMzMvgucbM3MysDJ1sysDJxszczKwMnWzKwMnGzNzMrAydbMbAUkbSrppYLHXEmnSWoraYykt9KfbYq25XG2ZmbFSaoAPga2B04CZkbEhZIGAW0i4qyqXu+erZlZ9fQE3o6I94H9gWHp+mHAAcVe7GRrZlY9fYHb0+drRMQUgPRnx2IvdhnBzHKrxaptY/GSr2r8+s+/nP8asLBg1dCIGLrsfpJWASYDW0bEVEmzI6J1wfZZEVFl3bZxjaM0M8vY4iVfsdGaP6jx61/54OmFEbFNNXbtBbwYEVPT5amSOkXEFEmdgGnFGnAZwcxyTVKNHyvhML4uIQA8APRPn/cH7i/WgJOtmVkVJDUH9gT+WbD6QmBPSW+l2y4s1o7LCGaWY0IqbZ8xIj4D2i2zbgbJ6IRqc8/WzKwM3LM1s1xrxErVXjPjnq2ZWRm4Z2tmuSVY2VEFmXHP1sysDNyzNbNca1Ti0Qh1xcnWzPJr5S9OyEw+/iSYmeWce7Zmlmvy0C8zM6vknq2Z5ZbIzwmyfERpZpZz7tmaWa55NIKZmS3lnq2Z5Zho5J6tmZlVcs/WzHJLgHLSZ3SyNbNc8wkyMzNbyj1bM8sv4RNkZmb2NfdszSzHlJuJaJxszSy3PDeCmZl9g5OtmVkZuIxgZrmWl3G2TrZmlmOeG8HMzAo42ZqZlYHLCGaWW8lENPkoIzjZmlmu5WWcrZOtmeWX8jMaIR9/Eiy3JK0q6UFJcyT9oxbt9JP0SF3GlhVJP5T0n6zjsPJysjUAJB0uaaKk+ZKmSHpY0i510PQhwBpAu4g4tKaNRMTwiNirDuIpKUkhaaOq9omIsRGxablisvrBZQRD0unAIOBEYDTwJbA3sD/wTC2bXx/4b0QsqmU7DYKkxv5/UXfkcbaWF5JaAecDJ0XEPyNiQUR8FREPRsSZ6T5NJV0maXL6uExS03TbbpI+kvQrSdPSXvHR6bbzgLOBPmmP+VhJ50r6e8H7d057g43T5aMkvSNpnqR3JfUrWP9Mwet2kjQhLU9MkLRTwbYnJf1B0rNpO49Iar+C46+Mf2BB/AdI2kfSfyXNlPSbgv23k/ScpNnpvldKWiXd9nS628vp8fYpaP8sSZ8AN1WuS1/TJX2PH6TLa0maLmm3Wn2w3yGqxX/l5GRrOwLNgHur2Oe3wA5AN6ArsB3wu4LtawKtgLWBY4GrJLWJiHOAPwN3RsTqEXFDVYFIWg24HOgVES2AnYCXlrNfW2Bkum874BJgpKR2BbsdDhwNdARWAc6o4q3XJPl/sDbJH4frgCOA7sAPgbMlbZjuuxj4JdCe5P9dT2AAQETsmu7TNT3eOwvab0vSyz++8I0j4m3gLGC4pObATcDNEfFkFfFaDjnZWjtgepGvtv2A8yNiWkR8CpwHHFmw/at0+1cR8RAwH6hpTXIJsJWkVSNiSkS8tpx9egNvRcStEbEoIm4H3gR+UrDPTRHx34j4HLiL5A/FinwF/CkivgLuIEmkQyJiXvr+rwHfB4iIFyJiXPq+7wHXAj+qxjGdExFfpPF8Q0RcB7wFjAc6kfxxswbGydZmAO0rv8avwFrA+wXL76frlraxTLL+DFh9ZQOJiAVAH5La8RRJIyVtVo14KmNau2D5k5WIZ0ZELE6fVybDqQXbP698vaRNJI2Q9ImkuSQ99+WWKAp8GhELi+xzHbAVcEVEfFFkXysgqcaPcnKyteeAhcABVewzmeQrcKX10nU1sQBoXrC8ZuHGiBgdEXuS9PDeJElCxeKpjOnjGsa0Mv5GEtfGEdES+A0ULf5FVRslrQ5cBtwAnJuWSayaGkk1fpQ1zrK+m9U7ETGHpE55VXpiqLmkJpJ6Sboo3e124HeSOqQnms4G/r6iNot4CdhV0nrpyblfV26QtIak/dLa7Rck5YjFy2njIWCTdLhaY0l9gC2AETWMaWW0AOYC89Ne98+X2T4V2PBbr6raEOCFiPgZSS36mlpHafWOk60REZcAp5Oc9PoU+BA4Gbgv3eWPwERgEvAK8GK6ribvNQa4M23rBb6ZIBsBvyLpuc4kqYUOWE4bM4B9031nAAOBfSNiek1iWklnkJx8m0fS675zme3nAsPS0Qr/V6wxSfuTDLM7MV11OvCDylEYlj1JrSXdLelNSW9I2lFSW0ljJL2V/mxTtJ2IKr/hmJnVW22at4vdNu1d49ff99KtL0TENlXtI2kYMDYirk+H+TUnKR/NjIgLJQ0C2kTEWVW144sazCzHVNKJaCS1BHYFjgKIiC+BL9NvJLuluw0DniQZwrdCLiOYWX6p5KMRNiQprd0k6d+Srk/PKawREVMA0p8dizXkZGtm32XtlcwJUvk4fpntjYEfAH+LiK1JRtMMqskbuYxgZt9l04vUbD8CPoqI8eny3STJdqqkThExRVInYFqxN3LP1sxyS5R2nG1EfAJ8KKnyisiewOvAA0D/dF1/4P5ibblnuxzNmqwaLZq1zDqMklizY4usQyipRo0rsg6hZNSAj+3DyZOZMWt2ja4yKMOEMr8gmbtiFeAdkjk3GgF3SToW+AAoOn2ok+1ytGjWkoO79ck6jJI48+QeWYdQUqut2TrrEEpmlTYN9w/l7of9NOsQVigiXgKWV2rouTLtuIxgZlYG7tmaWY7lZ/JwJ1szyy2Rnxs+OtmaWa7lpWfrmq2ZWRk42ZqZlYHLCGaWa+W+cWNNOdmaWW5JrtmamVkBJ1szszJwGcHMcqz8d8mtKSdbM8s112zNzGwp92zNLNfyMvTLPVszszJwz9bMcqvyTg154GRrZrmWl9EILiOYmZWBe7Zl9qe7zmHhZ1+wZMkSlixewgXHDWbfo3uxy092ZN7s+QDcP3QEr457PeNIV96ga67k8Rcn0q5lKx4ePGTp+ltGjeTW0Q9TUVFBj627c1a/+nsLlOq67u57GD5iJEHQr3dvjj/0kKxDqlOLFy+m52E/pVPHjtx+5aVZh9MgONlm4JJTr2DBnAXfWPfYXU8y5o7HM4qobhz0ox4c8eNenHnV5UvXPffaKzw6cQIjLrqUpk2aMGPO7AwjrBtvvvMuw0eM5KFrrmaVxk04fOBZ7LHjDmy4zjpZh1Znrh1+B5tsuAHz5i8ovnOWqnmX3PrAZQSrM9ttviWtV/vmTQlvGzOaE/Y/kKZNmgDQrlX+b8j41gfv032LLWjerBmNG1ewQ7euPDz2mazDqjMfT53KI2Of4YgD9886lKIq79RQ00c5uWdbZhFw6iUDiICx9z/LMw/+C4DdDvoh2++9Le+/+SH3XHkvn83/PONI68Z7UyYz4c03uOSO21hllSb8+oj+fL/LxlmHVSubbrABF15/IzPnzKFZ06Y8Pm48XTfdJOuw6sxvL7qEc395CvMXfJZ1KA2Kk22ZXTzgUubMmEuL1qtz6qUn8ckHU3nqvmcYOWwUBOz3s304+OQDufXC27IOtU4sWryYuQvmc/cfL2TS2//jlMv+yhOX/y03Z5CXZ5P11+ekw/rS54wzWW3VVdmiSxcqKiqyDqtOjH5qLO3btqHbFpvzzIQXsg6nWnxRQz2lRGbHPWfGXADmzZ7PS09PYoPN12ferHnEkiAieObB5+i8+XpZhVfn1mzXjr223QFJdN1oYyQxc97crMOqtcN778OY64Zy3+VDaN2yRYOp145/6WVGPTmWbr3247izfsPYCRM44de/zzqsBqHeJFtJ90l6QdJrko5P182X9CdJL0saJ2mNdH2XdHmCpPMlzS9o58x0/SRJ56XrOkt6Q9LVwIvAulkc4yrNVqHpqk2XPt982834+J0ptGzXcuk+3Xb9PpPfnZJFeCWx5zbbM+61VwB4d/Jkvlq0iLYtWhZ5Vf03fdYsAD6aOpWHnh7LAT13zziiunH2qSfz6piRvPTwA1z3lz/zw2235doL/pB1WFVqpJo/yqk+lRGOiYiZklYFJki6B1gNGBcRv5V0EXAc8EdgCDAkIm6XdGJlA5L2AjYGtiOpnT8gaVfgA2BT4OiIGFDew/payzYtOPHPPwOgUUUjJox5gdeff4Ojfnck6260NkEwY8pMhg++M6sQa+W0yy9h/OuvMmvePHYe8DNOPaQvh/TYnUHXXEWvM06lSePGXDzglFyXECode/a5zJo7lyaNK7jgtFNp3aJF8RfZd5oiIusYAJB0LnBgutgZ+DHwFNAsIkJSH2DPiPiZpBnAGhGxSFJLYHJErC5pMHAIUDm+aHXgAuAx4ImI2KCK9z8eOB5g9aYtuvfb9qi6PsR64cyTe2QdQkmttmb+RzusyCptGm5C3/2wn/LSa6+v9F/hji3WiD7dD6/x+1751GUvRMQ2NW5gJdSLnq2k3YA9gB0j4jNJTwLNgK/i678Giyker4ALIuLaZdrvDFQ5YDAihgJDATq0WKN+/AUyswajvtRsWwGz0kS7GbBDkf3HAQenz/sWrB8NHCNpdQBJa0vqWOfRmlm9UDkRTU0f5VQverbAKOBESZOA/5Ak06qcBvxd0q+AkcAcgIh4RNLmwHNpXXA+cARJr9jMGpoMLk6oqXqRbCPiC6DXcjatXrDP3cDd6eLHwA5pLbcvMLFgvyEkJ9CWtVXdRWxmtnLqRbKtge7AlUr+pM0Gjsk4HjPLSKOcXNSQy2QbEWOBrlnHYWZWXblMtmZm8PVENHlQX0YjmJk1aO7Zmlmu5WU+WydbM8u1nORalxHMzMrBydbMrAxcRjCz3Kq8XDcPnGzNLMeUmzs1ONmamVVB0nvAPJI5VhZFxDaS2gJ3kkwH+x7wfxExq6p2XLM1s/xS2e6u2yMiuhXMfTsIeCwiNiaZL3tQsQacbM3MVt7+wLD0+TDggGIvcBnBzHKtlifI2kuaWLA8NL2RQKEAHpEUwLXp9jUiYgpAREypzrzZTrZmllvJ3Ai1amJ6NW6Ls3NETE4T6hhJb9bkjVxGMDOrQkRMTn9OA+4luaHsVEmdANKf04q142RrZrYCklaT1KLyObAX8CrwANA/3a0/cH+xtlxGMLNcK/FFDWsA96YjFxoDt0XEKEkTgLskHQt8ABxarCEnWzPLtVJe1BAR77CcGxVExAyg58q05TKCmVkZuGdrZrklyn9L8ppyz9bMrAzcs12ONTu24KzT9sg6jJLY7/TBWYdQUmNuOS/rEEpm1hsfZh1CySxe+GXNXqj8TB7uZGtmueYbPpqZ2VJOtmZmZeAygpnlWl5GIzjZmllu1cFENGXjMoKZWRk42ZqZlYHLCGaWa67ZmpmVge+ua2ZWait/48bMuGZrZlYGTrZmZmXgMoKZ5ZaARvmoIjjZmlm+uWZrZmZLOdmamZWBywhmlmt5KSM42ZpZbkn5OUHmMoKZWRmssGcr6RUglrcJiIj4fsmiaqAGXnU5T7wwkXatWjHq0isAuOzO27nzsUdo27IVAGccfgQ9frBNlmHWSOcN1+XiK89durzOemtx1SU38sA9oxh81bmstU4nJn80hTMGnMPcufOzC7SOXHf3PQwfMZIg6Ne7N8cfekjWIdXYoGuu5PEXJ9KuZSseHjxk6fpbRo3k1tEPU1FRQY+tu3NWv59mGGX+VVVG2LdsUXxHHNKjJz/t1ZszrrjsG+uP6b0fx+1/YEZR1Y333vmQQ/c5FoBGjRrx2Ph7eGz00xw7oB/jn32RG/42nGN/3o9jBxzBpRdek3G0tfPmO+8yfMRIHrrmalZp3ITDB57FHjvuwIbrrJN1aDVy0I96cMSPe3HmVZcvXffca6/w6MQJjLjoUpo2acKMObMzjLBqeanZrrCMEBHvVz7SVRunz6cBM8sSXQOz3RZb0nr11bMOo+S237k7H34wmSkfT6XHnrtw/z2jALj/nlH02GuXjKOrvbc+eJ/uW2xB82bNaNy4gh26deXhsc9kHVaNbbf5lrRercU31t02ZjQn7H8gTZs0AaBdq9ZZhFYtUs0f5VS0ZivpOOBu4Np01TrAfaUM6rvmllEP0ev0Uxh41eXMmZ//r9i99tudhx94DIB27dswfdoMAKZPm0G79m2yDK1ObLrBBoybNImZc+bw2cKFPD5uPJOnTcs6rDr13pTJTHjzDQ7+7Vkcdt7vmPT2W1mHtEKNpBo/yhpnNfY5CdgZmAsQEW8BHUsZ1IpIOkXSG5KGZ/H+pdDvx7148sprGDn4Mjq2acOfht2YdUi10rhJY3bbY2ceGflE1qGUzCbrr89Jh/WlzxlncvjAs9iiSxcqKiqyDqtOLVq8mLkL5nP3Hy9kUL/+nHLZX4lY3ikcq67qJNsvIuLLygVJjVn+ibNyGADsExH9atqApHr1r6JD69ZUVFTQqFEj+u6xF5P+V397ENXxw9124I1X32LG9FkAzJg+i/Yd2wHQvmO7pevz7vDe+zDmuqHcd/kQWrdskdt67Yqs2a4de227A5LoutHGSGLmvLlZh5Vr1Um2T0n6DbCqpD2BfwAPljasb5N0DbAh8ICk30q6UdIESf+WtH+6T2dJYyW9mD52StfvJukJSbcBr5Q79qpMm/V1+Xv0+HFssu56GUZTe73268nDDzy6dPnJR59l/4P3BmD/g/fmiTH5rW0Wmj4r+aPx0dSpPPT0WA7ouXvGEdWtPbfZnnGvJf9U3p08ma8WLaJti5YZR/VtquV/5VSdixoGAceSJKkTgIeA60sZ1PJExImS9gZ6AKcDj0fEMZJaA89LepTk5N2eEbFQ0sbA7UDlOKrtgK0i4t1yx17plEsHM/61V5k1by47HX8Mp/Y5jPGvvcrr772LgHU6duRPJwzIKrxaa9asKTv+cBvO/83gpetuuHo4g68+jwP79GbK5Kn86udnZxhh3Tn27HOZNXcuTRpXcMFpp9K6RYviL6qnTrv8Esa//iqz5s1j5wE/49RD+nJIj90ZdM1V9DrjVJo0bszFA06pt2f962lY31I02UbEEknDgPEk5YP/RPbFm72A/SSdkS43A9YDJgNXSuoGLAY2KXjN81UlWknHA8cDrNW+Q0mCvvyXZ3xrXZ+ee5bkvbKwcOEX/LDbT76xbs7suRx3+C8ziqh07r9iSPGdcuKyU05f7vpLTj6tzJE0bEWTraTewDXA2yQXNGwg6YSIeLjUwVUVFnBwRPznGyulc4GpQFeSEsnCgs0LqmowIoYCQwG+12WjrP+YmFkDU52a7V+BHhGxW0T8iORr/KWlDauo0cAvlH6vkbR1ur4VMCUilgBHAvXqZJiZ1TE1rKFf0yLifwXL75DURrP0B6AJMEnSq+kywNVAf0njSEoIVfZmzSz/lN70sSaPcqpqboSD0qevSXoIuIukZnsoMKEMsX1LRHQuWDxhOdvfAgrnbPh1uv5J4MkShmZmVqWqaraFZzqmAj9Kn38K5P8yIDPLPdEARiNExNHlDMTMrCGrzmiEZiTjbLckGWIFQEQcU8K4zMyqpb6O/11WdU6Q3QqsCfwYeIpkIpp5pQzKzKy6Gqnmj7LGWY19NoqI3wMLImIY0Bv4XmnDMjOrPyRVpFMDjEiXN5A0XtJbku6UtEqxNqqTbL9Kf86WtBXJWNbONY7azCx/TgXeKFj+C3BpRGwMzCIptVapOsl2qKQ2wO+BB4DXgYtWPlYzszqm0o+zlbQOyTf669NlAbuTzPMNMAw4oFg71ZkboXLSmadIZt0yM6sXyjT06zJgIFA521A7YHZELEqXPwLWLtZIVRc1LH92ilREXFK9OM3M6q32kiYWLA9N50kBQNK+JFfRviBpt8rVy2mn6HwqVfVs8ztnnJl9R9R6joPpEVHV7ax3JplhcB+Soa8tSXq6rSU1Tnu365DMOFilqi5qOG/lYjYza1gi4tekl/2nPdszIqKfpH8AhwB3AP2B+4u1VZ0TZGZm9VZGE9GcBZwu6X8kNdwbir2gOndqMDOrl8o5N0LhhFYR8Q7J3V+qzT1bM7My8GgEM8sv5WduhOqMRtgU2JbkggZIpl58upRBmZk1NEVHI0h6BPhBRMxLl88luZ25mVnmctKxrVbNdj3gy4LlL/HcCGZmK6U6oxFuBZ6XdC/JVRIHAreUNCozs2oq940ba6o6cyP8SdLDwA/TVUdHxL9LG5aZWcNS3XG2zYG5EXGTpA6SNoiId0sZmJlZMXm6B1nRmq2kc0iulvh1uqoJ8PdSBmVm1tBUp2d7ILA18CJAREyW5ElqzKxeaAjjbCt9GREhKQAkrVbimDJX0bQJLTdcM+swSmLklWdlHUJJ/eHsovOB5NY5fzkk6xBKpmKVGs4coAZURgDuknQtyZRixwGPks5YbmZm1VOd0QiDJe0JzCW5muzsiBhT8sjMzIqq9exdZVM02Ur6S0ScBYxZzjozM6uG6pQR9lzOul51HYiZWU1INX+UU1Wzfv0cGAB0kTSpYFML4F+lDszMrCGpqoxwG/AwcAEwqGD9vIiYWdKozMyqQeTnct0VlhEiYk5EvAcMAWZGxPsR8T7wlaTtyxWgmVlDUJ2a7d+A+QXLC9J1ZmaZy33NtoAiYuk90SNiiSTfu8zMspejOzVUp2f7jqRTJDVJH6cC75Q6MDOzhqQ6yfZEYCfgY+AjYHvg+FIGZWbW0FTnCrJpQN8yxGJmttJyUkWocpztwIi4SNIVJHdo+IaIOKWkkZmZFZHMZ5uPbFtVz/aN9OfEcgRiZtaQVXV33QfTn8PKF46Z2crJSce2yjLCgyynfFApIvYrSURmZg1QVWWEwenPg4A1+fpWOIcB75UwJjOzast9zTYingKQ9IeI2LVg04OSni55ZGZmxTSwOzV0kLRh5YKkDYAOpQvJzKzhqc5lt78EnpRUedVYZ+CEkkX0HbJ17wNYfbXmVDRqREVFBY8Nz/e5yDOGXMbjEyfQrlUrxlx5NQCD/34rY8aPp1Ej0a5Va/566mms0a5dxpHWzPl3nM3CzxcSi4PFixdz0QmXLN3Ws08PDhqwPwP3+y0L5izIMMra+d/7H3D8789Zuvz+x5MZeNyxnND3/zKMqmGozkUNoyRtDGyWrnozIr4obVjfHfddezXt2rTOOow6cWjPPei/776cfunXSeiEgw7mjCOOBOCmBx9gyJ238+cBJ2cVYq0NOe2qbyXT1h1as9k2mzLzk/zPPLrR+uvx+C03AbB48WK67ncQ+/xo1yKvylJ+botTtIwgqTlwJnByRLwMrCdp35JHZrmz/VZb0Xr1b97lvkXz5kuff7ZwISIf/zBWxiEnH8B91zxArHDsTj6NnfgCnddei3U71d87TScXNTScWb9uAl4AdkyXPwL+AYwoVVDfFRIcctIpCOh/8IH0P/jArEMqiYtuvYV/PvE4LZo3544/XZB1ODUWBCcPPhECnnnwXzz74HN8b6ctmT19Dh+/PTnr8OrcvWMe48A998g6jKLyMnl4dZJtl4joI+kwgIj4XPWs3y7pXxGxU9ZxrKyRN11Hpw4d+HTmTA75+S/YuHNnduq+ddZh1bmBR/6UgUf+lKv+cRfDRo7g9MP7ZR1SjVxy0hDmzJjL6q1X5xd//TlT35/K3kfuxRVnNLzpnb/86iseeeZZfjvAp2fqSnVGI3wpaVXSCxwkdQHqVc02j4kWoFOHZFBHh7Zt2afHbrz42msZR1Ra+/9oNx7+17NZh1Fjc2bMBWD+7Pm8PPYVNuq2Ee06teU3Nwzk/DvOpnWHVgy67gxatm1RpKX677HnxvG9TTehY9u2WYfSYFQn2Z4DjALWlTQceAwYWNKoVpKk+UpcLOlVSa9I6pNuu1XS/gX7DpeU+dVvCz7/nHkLFix9/uS48WzepUvGUdW9dyd/vPT5mOfH02WddTKMpuZWabYKTVdtuvT55ttuygdvfsCgA37P2X3P5+y+5zP70zlceNxg5s6cl3G0tXfvmEc5cM+eWYdRLQ2iZpuWC94kuYpsB5J69KkRMb0Msa2sg4BuQFegPTAhvfjiepLha/dLakUyN2//zKJMfTpjJv1/lfzNWrR4MQfv/WN67rxjkVfVb7+4+CKee/UVZs2dy/ZH9+eXh/XjiRcm8s7HH9FIjVi7Ywf+POCkrMOskRZtWnD8H48BoKKiERMefZHXn38z46hK47OFC3n6+YkMPuvMrEMpLkd3aqgy2UZESLovIroDI8sUU03tAtweEYuBqZKeAraNiAckXSWpI0lCviciFi37YknHk06Kvs6apT/72nmdtXnqzuElf59yuuLMb3/h6bvXXhlEUvdmTJnBBcdeXOU+Z/c9v0zRlFbzZs14c3R9/+eeP9UpI4yTtG3JI6m9qv683Qr0A44mGV3xLRExNCK2iYhtGsq4VzOrP6qTbHuQJNy3JU1K66GTSh1YDTwN9JFUIakDsCvwfLrtZuA0gIho2GehzL5DGto4214lj6L2AriXZCzwy+nywIj4BCAipkp6A7gvuxDNrBTUqHRZU1Izko5cU5J8eXdEnJPOEXMH0BZ4ETgyIr6sqq2q5rNtRnKzx42AV4AbllfrzJqkdsDM9HbrZ6aPZfdpDmwM3F7m8Mws374Ado+I+ZKaAM9Iehg4Hbg0Iu6QdA1wLFDlgOuqygjDgG1IEm0v4K91EnodkrQW8Bxfz727vH32IBlRcUVEzClXbGaWf5GYny42SR8B7A7cna4fBhxQrK2qyghbRMT3ACTdwNf1z3ojIiYDmxTZ51FgvfJEZGblVuraq6QKkikLNgKuAt4GZhd80/8IWLtYO1Ul268qn0TEoryMZTOz75Daj7NtL6nwprZDI2Jo4Q7pcNJuklqTnBvafDntFJ2GqKpk21XS3PS5gFXTZSXvHy2LNW5mVmq17AdOj4htqrNjRMyW9CTJBV6tJTVOe7frAEVnIpyFkW4AABD/SURBVFphzTYiKiKiZfpoERGNC5470ZpZgyepQ9qjJZ0jZg/gDeAJ4JB0t/7A/cXaqs7QLzOz76pOwLC0btsIuCsiRkh6HbhD0h+BfwM3FGvIydbMckslvlNDREwCvjXvaUS8A2y3Mm052ZpZruXl3H11Ltc1M7NacrI1MysDlxHMLN9yUkdwsjWz/MrR5OEuI5iZlYGTrZlZGbiMYGa5lpMqgpOtmeVbKScPr0tOtmaWW5W3xckD12zNzMrAydbMrAxcRjCz/MrROFsnWzPLtZzkWpcRzMzKwT3b5YjFS/hq7oKswyiJJYuWZB1CSf3+/P2zDqFk7r3imaxDKJlZ0+YX32m5SjufbV1yz9bMrAzcszWzXMtJx9Y9WzOzcnDP1sxyK7mCLB9dW/dszczKwD1bM8svkZsuo5OtmeWaywhmZraUe7Zmlms56di6Z2tmVg7u2ZpZrrlma2ZmS7lna2b5JddszcysgHu2ZpZj+enaOtmaWW6J/NzK3GUEM7MycM/WzHItJ1UE92zNzMrBPdsMXXf3PQwfMZIg6Ne7N8cfekjWIdXKwCuH8PjEibRr1YrRQ678xrah993LBbfcxAs3/522LVtmFGHdaWifHSQXBxz0x6NYMGseowbfze4DfkKHDdZkyeIlTHt7CmNvHMWSxfXsHnY5upW5e7YZefOddxk+YiQPXXM1j11/PY8+N453Pvoo67Bq5eAePbn59+d+a/3k6Z/yzKSXWKt9h/IHVQIN8bMD2GrvbZg1efrS5beefY07z7yOfwy6gcarNGaz3bpmGF3+Odlm5K0P3qf7FlvQvFkzGjeuYIduXXl4bL7vnrr9llvRusXq31r/hxtvYNCRR+WmB1JMQ/zsVmvbgvW7deHNJyYtXffhy+8sfT7t7Sms1rZFFqEVJdX8UU5OthnZdIMNGDdpEjPnzOGzhQt5fNx4Jk+blnVYdW7M8+NZs107tthgg6xDqTMN8bPb6ciejLv9CSLiW9saVTRi41225MNJ7yznlVZd9a5mK6kzMCIitso4lJLaZP31OemwvvQ540xWW3VVtujShYqKiqzDqlOff/EFV93zD245+7ysQ6lTDe2zW2/rLnw+5zOmvzeVTpuv963tuxy9F5+8+SGf/Keelkpy8o2p3iXb75LDe+/D4b33AeDP113PWh0aRk2z0vufTOGjqVPZ5/RTAfhkxnR+csZp3PeXv9KhTZuMo6udhvTZrbnJOqzffSPW69aFiiYVNFm1Kbv/fF8e/9sIuh+0M81aNOeRG/6ZdZiZkLQucAuwJrAEGBoRQyS1Be4EOgPvAf8XEbOqaqtkyVbSasBdwDpABfAHYFPgJ8CqwL+AEyIiJHUHbgQ+A54paOMoYD+gOdAFuDciBqbb9gLOA5oCbwNHR8R8SRemr1kEPBIRZ0g6FDgHWAzMiYhdS3XcK2P6rFm0b9OGj6ZO5aGnxzLi6iuLvyhHNlu/MxNvvnXp8i4n/IwHLr6kQYxGaEif3fN3PsXzdz4FQKfN16Nr7+14/G8j2Gy377PO9zZgxJ/vgG9XF+qNEl9Btgj4VUS8KKkF8IKkMcBRwGMRcaGkQcAg4KyqGiplz3ZvYHJE9AaQ1AoYExHnp8u3AvsCDwI3Ab+IiKckXbxMO92ArYEvgP9IugL4HPgdsEdELJB0FnC6pCuBA4HN0iTeOm3jbODHEfFxwbrMHXv2ucyaO5cmjSu44LRTad2ifp6AqK5TLrmYca++yqx5c9nxZ0dzWt/D6LPHXlmHVRIN7bNbnh8eszfzps/hgPOOBODdCf/lxXufzTiqbyr1ia6ImAJMSZ/Pk/QGsDawP7Bbutsw4EkyTLavAIMl/YWkBjtW0sGSBpL0VNsCr0l6GmgdEU+lr7sV6FXQzmMRMQdA0uvA+kBrYAvg2fQM9yrAc8BcYCFwvaSRwIi0jWeBmyXdBSz3+5Ck44HjAdZeY426OP6i7r9iSFnep1wuP/3MKrc/c+31ZYqk9BraZ1dpyhsfMOWNDwC47qcXZRxN/ZKeT9oaGA+skSZiImKKpI7FXl+yZBsR/03LA/sAF0h6BDgJ2CYiPpR0LtCMZC6Jqr6kfFHwfDFJzCLpJR+27M6StgN6An2Bk4HdI+JESdsDvYGXJHWLiBnLxDsUGArQddNN6/GXJjP7Wq27tu0lTSxYHprmgm++i7Q6cA9wWkTMrckwxlLWbNcCZkbE3yXNJ6lxAExPAz8EuDsiZkuaI2mXiHgG6FeN5scBV0naKCL+J6k5SW14MtA8Ih6SNA74XxpLl4gYD4yX9BNgXWDGiho3s++M6RGxTVU7SGpCkmiHR0TlN+OpkjqlvdpOQNGxf6UsI3wPuFjSEuAr4OfAASTlhfeACQX7Hg3cKOkzYHSxhiPi0/Tk2e2SmqarfwfMA+6XVNlj/mW67WJJG6frHgNert2hmVl9UcqarZIu7A3AGxFxScGmB4D+wIXpz/uLtVXKMsJovp04J5IkxWX3fQEovBbw3HT9zcDNBfvtW/D8cWDb5bz1dstp/6BqB25muVLi0Qg7A0cCr0h6KV33G5Ike5ekY4EPgEOLNeRxtmZmK5CWNleUzXuuTFu+XNfMrAzcszWz/MrRFItOtmaWb/nItS4jmJmVg5OtmVkZuIxgZrnmmq2ZWYkJJ1szs9ITuSmG5iRMM7N8c7I1MysDlxHMLMfkmq2ZWTnkJdm6jGBmVgZOtmZmZeAygpnlWz6qCE62ZpZjKvnk4XXGZQQzszJwsjUzKwOXEcws33Iy9MvJ1sxyLSe51snWzPIrT7N+uWZrZlYG7tkux6T//nd6p912f7+Mb9kemF7G9ysnH1t+lfP41i/T+2TGyXY5IqJDOd9P0sSI2Kac71kuPrb8ysXxSZCTcbZOtmaWa67ZmpnZUk629cPQrAMoIR9bfjX04ysrlxHqgYhosL/UPrb8ys3x5aOK4GRrZvnmmq01eJJOkfSGpOFZx1Jqkv6VdQylIqmzpFezjqNG0lm/avooJ/dsc0rJn3NFxJIMwxgA9IqId2vagKSKiFhchzGVRETslHUMlm/u2dYxSfdJekHSa5KOT9fNl/QnSS9LGidpjXR9l3R5gqTzJc0vaOfMdP0kSeel6zqnPcmrgReBdbM4xjSWa4ANgQck/VbSjWm8/5a0f0G8YyW9mD52StfvJukJSbcBr2R1DCsj/Qwl6WJJr0p6RVKfdNutlcecLg+XtF8GMa4maWT6e/aqpD6Szk4/l1clDU3/SCOpe7rfc8BJBW0cJemfkkZJekvSRQXb9pL0XPpZ/kPS6un6CyW9nv6uDk7XHZq+58uSni7z/4p6ycm27h0TEd2BbYBTJLUDVgPGRURX4GnguHTfIcCQiNgWmFzZgKS9gI2B7YBuQHdJu6abNwVuiYitI6KcV7l9Q0ScSBJzD5Ljezw9jh7AxZJWA6YBe0bED4A+wOUFTWwH/DYitihv5LVyEMnn0RXYg+Q4OwHXA0cDSGoF7AQ8lEF8ewOTI6JrRGwFjAKujIht0+VVgX3TfW8CTomIHZfTTjeSz+t7QB9J60pqD/wO2CP9PCcCp0tqCxwIbBkR3wf+mLZxNvDj9He+tH94pJo/ysjJtu6dIullYBxJz3Nj4EtgRLr9BaBz+nxH4B/p89sK2tgrffybpAe7WdoOwPsRMa5UwdfQXsAgSS8BTwLNgPWAJsB1kl4hOc7CxPp8bcoPGdkFuD0iFkfEVOApYNuIeArYSFJH4DDgnohYlEF8rwB7SPqLpB9GxBygh6Tx6WewO7Bl+gehdRo3wK3LtPNYRMyJiIXA6ySX0u5A8vk9m37O/dP1c4GFwPWSDgI+S9t4FrhZ0nFARcmOOL2VeU0f5eSabR2StBtJj2fHiPhM0pMkieeriIh0t8UU//8u4IKIuHaZ9jsDC+ow5Loi4OCI+M83VkrnAlNJeoKNSP5RVqqPx1FMVf86bwX6AX2BY8oTzjdFxH8ldQf2AS6Q9AhJiWCbiPgw/TyakRxHrLglvih4Xvn7KmBMRBy27M6StgN6khz7ycDuEXGipO2B3sBLkrpFxIxaH2SOuWdbt1oBs9JEuxlJb6Aq44CD0+d9C9aPBo4pqImtnfaa6qvRwC8K6oFbp+tbAVPSk3hHUtIeTlk8TfK1ukJSB2BX4Pl0283AaQAR8VoWwUlaC/gsIv4ODAZ+kG6anv4uHZLGNxuYI2mXdHu/ajQ/DthZ0kbpezWXtEnabquIeIjk+Lul27tExPiIOJtkMpvMzi/UF+7Z1q1RwImSJgH/IfkFrcppwN8l/QoYCcwBiIhHJG0OPJfmr/nAESS9jProD8BlwKQ04b5HUhu8GrhH0qHAE+SzN1spgHtJSj8vp8sDI+ITgIiYKukN4L7sQuR7JHXkJcBXwM+BA0jKC+8BEwr2PRq4UdJnJH8sqxQRn0o6CrhdUtN09e+AecD9kip7zL9Mt10saeN03WMk/89KIx/DbNHX326t3CQ1Bz6PiJDUFzgsIvYv9jorr/Qk54sRscJpANPP8hXgB2mt1Mqg6yabxENXXFHj16+z994vlGtmM/dss9UduDLtDc4mo1qfrVj61fxJkq/lK9pnD+BG4BInWlsRJ9sMRcRYkpNHVk9FxGRgkyL7PEoy+sKy4Mt1zcyskpOtmeVaqcfZKrk6cpoK5o+Q1FbSmPQquzGS2hRrx8nWzPJLJLfFqemjem4muTqv0CCSiz82JhltMahYI062VjaS2kl6KX18IunjguVV6vB99pBU5RAsST+TdNlKtvuRpNa1i87yJiKeBmYus3p/YFj6fBjJELsq+QSZlU16BVHloPdzgfkR8Y2z/OnIjKxnMzMrZo2ImAIQEVOqc9GRe7aWOUkbKZkh6hrS2cwkzS7Y3lfS9enzNZTMSjVR0vOSqrxKT9IOSmaq+rekZ9OB9pXWlzRa0n8k/a7gNf3Ttl+SdLUk/zupt2o9N0L79Hep8nF8qSJ1z9bqiy2Ao9Nr6qv6vbwcuCgiximZK2IEsFUV+78B7BIRiyXtTTIrVZ9023bpa78EJkgaASwimcVqp4hYJGkoyaXUt327aasXajfya3oNL2qYKqlT2qvtRDLDXZWcbK2+eDsiJhTfjT2ATQvOJLeRtGpEfL6C/VsDt0jqspxtoyNiFiTzEJPM6tUY2BaYmL7HqsCH1T8M+454gGTmswvTn/cXe4GTrdUXhfMmLOGb/ZVmBc8FbBcRX1az3T+RJNWr00lURhVsW/Za9UjbvzEifl/N9i1j1R3CVYv2bwd2Iyk5fAScQ5Jk75J0LPABcGixdpxsrd6JiCWSZqX11bdJvtZ/mm5+lGTawEsBlEzd91IVzbUCPk6fH7XMtr3S0QVfkpxd7kcy2c/dkoZExPR0XoTVIuKDOjg0y6HlTSuZ6rky7bjwb/XVWSS90MeAjwrWn0Qy1d8kSa/z9V0vVuQvJDNQPbucbc+Q1GL/TTIp+EsR8QpwHvCoktnbHgHWqN2hWMmUZ5xt3YTqWb/MLK+6brZpjB56TY1f3+lHu3vWLzOz6ih1zbauuIxgZlYG7tmaWb7lpGfrZGtmuSXKf5fcmnIZwcysDNyzNbP8qhz6lQPu2ZqZlYF7tmaWa67ZmpnZUu7Zmlm+5aRn62RrZrkmnyAzM7NKTrZmZmXgMoKZ5Zfkmq2ZWTl46JeZmS3lnq2Z5Zt7tmZmVsk9WzPLtbyMs3WyNbP8Ei4jmJnZ15xszczKwGUEM8ux/FzUoIjIOgYzsxqRNApoX4smpkfE3nUVT1WcbM3MysA1WzOzMnCyNTMrAydbM7MycLI1MysDJ1szszL4f66lbkBKrzJ1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot your confusion matrix\n",
    "my_tags = ['anger', 'fear', 'joy', 'sadness']\n",
    "plot_confusion_matrix(cm, classes=my_tags, title='Confusion matrix')\n",
    "\n",
    "# diagonal values: are the ones we predict correctly. everything else around it is mis classified\n",
    "# out of the total XX squares, 70 cases of fear were predicted correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 3 (Take home): **  \n",
    "Can you interpret the results above? What do they mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 4 (Take home): **  \n",
    "Build a model using a ```Naive Bayes``` model and train it. What are the testing results? \n",
    "\n",
    "*Reference*: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 5 (Take home): **  \n",
    "\n",
    "How do the results from the Naive Bayes model and the Decision Tree model compare? How do you interpret these differences? Use the theoretical background covered in class to try and explain these differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Other things you can try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, there are several things you can try that will affect your results. In order to yield better results, you can experiment by: \n",
    "    * Trying different features (Feature engineering)\n",
    "        -Eg. Word2Vec,PCA,LDA,FastText, Clustering......\n",
    "    * Trying different models\n",
    "    * Analyzing your results and interpret them to improve your feature engineering/model building process\n",
    "    * Iterate through the steps above until finding a satisfying result\n",
    "Remember that you should also consider the task at hand and the model you'll feed the data to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Deep Learning\n",
    "\n",
    "We use [Keras](https://keras.io/) to be our deep learning framwork, and follow the [Model (functional API)](https://keras.io/models/model/) to build a Deep Neural Network (DNN) model. Keras runs with Tensorflow in the backend. It's a nice abstraction to start working with NN models. \n",
    "\n",
    "Because Deep Learning is a 1-semester course, we can't talk about each detail about it in the lab session. Here, we only provide a simple template about how to build & run a DL model successfully. You can follow this template to design your model.\n",
    "\n",
    "We will begin by building a fully connected network, which looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fully Connected Network](pics/pic1.png)\n",
    "\n",
    "(source: https://github.com/drewnoff/spark-notebook-ml-labs/tree/master/labs/DLFramework)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Prepare data (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (3613, 500)\n",
      "y_train.shape:  (3613,)\n",
      "X_test.shape:  (347, 500)\n",
      "y_test.shape:  (347,)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# standardize name (X, y) \n",
    "X_train = BOW_500.transform(train_df['text'])\n",
    "y_train = train_df['emotion']\n",
    "\n",
    "X_test = BOW_500.transform(test_df['text'])\n",
    "y_test = test_df['emotion']\n",
    "\n",
    "## check dimension is a good habit \n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Deal with categorical label (y)\n",
    "\n",
    "Rather than put your label `train_df['emotion']` directly into a model, we have to process these categorical (or say nominal) label by ourselves. \n",
    "\n",
    "Here, we use the basic method [one-hot encoding](https://en.wikipedia.org/wiki/One-hot) to transform our categorical  labels to numerical ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check label:  ['anger' 'fear' 'joy' 'sadness']\n",
      "\n",
      "## Before convert\n",
      "y_train[0:4]:\n",
      " 487     anger\n",
      "2356      joy\n",
      "1164     fear\n",
      "1400     fear\n",
      "Name: emotion, dtype: object\n",
      "\n",
      "y_train.shape:  (3613,)\n",
      "y_test.shape:  (347,)\n",
      "\n",
      "\n",
      "## After convert\n",
      "y_train[0:4]:\n",
      " [[1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n",
      "\n",
      "y_train.shape:  (3613, 4)\n",
      "y_test.shape:  (347, 4)\n"
     ]
    }
   ],
   "source": [
    "## deal with label (string -> one-hot)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "print('check label: ', label_encoder.classes_)\n",
    "print('\\n## Before convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "y_test = label_encode(label_encoder, y_test)\n",
    "\n",
    "print('\\n\\n## After convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape:  500\n",
      "output_shape:  4\n"
     ]
    }
   ],
   "source": [
    "# I/O check\n",
    "input_shape = X_train.shape[1]\n",
    "print('input_shape: ', input_shape)\n",
    "\n",
    "output_shape = len(label_encoder.classes_)\n",
    "print('output_shape: ', output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imgur](pics/pic2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 500)]             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                32064     \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 36,484\n",
      "Trainable params: 36,484\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.layers import ReLU, Softmax\n",
    "# https://stackoverflow.com/questions/56986100/module-tensorflow-has-no-attribute-get-default-graph-i-dont-want-any-grap\n",
    "\n",
    "# input layer\n",
    "model_input = Input(shape=(input_shape, ))  # 500\n",
    "X = model_input\n",
    "\n",
    "# 1st hidden layer\n",
    "X_W1 = Dense(units=64)(X)  # 64\n",
    "H1 = ReLU()(X_W1)\n",
    "\n",
    "# 2nd hidden layer\n",
    "H1_W2 = Dense(units=64)(H1)  # 64\n",
    "H2 = ReLU()(H1_W2)\n",
    "\n",
    "# output layer\n",
    "H2_W3 = Dense(units=output_shape)(H2)  # 4\n",
    "H3 = Softmax()(H2_W3)\n",
    "\n",
    "model_output = H3\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[model_input], outputs=[model_output])\n",
    "\n",
    "# loss function & optimizer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# show model construction\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3613 samples, validate on 347 samples\n",
      "Epoch 1/25\n",
      "3613/3613 [==============================] - 2s 589us/sample - loss: 1.3173 - accuracy: 0.3656 - val_loss: 1.2487 - val_accuracy: 0.4640\n",
      "Epoch 2/25\n",
      "3613/3613 [==============================] - 1s 243us/sample - loss: 0.9630 - accuracy: 0.6573 - val_loss: 0.8935 - val_accuracy: 0.6801\n",
      "Epoch 3/25\n",
      "3613/3613 [==============================] - 1s 253us/sample - loss: 0.5687 - accuracy: 0.7952 - val_loss: 0.7449 - val_accuracy: 0.7061\n",
      "Epoch 4/25\n",
      "3613/3613 [==============================] - 1s 250us/sample - loss: 0.4240 - accuracy: 0.8403 - val_loss: 0.7376 - val_accuracy: 0.7233\n",
      "Epoch 5/25\n",
      "3613/3613 [==============================] - 1s 248us/sample - loss: 0.3424 - accuracy: 0.8705 - val_loss: 0.8105 - val_accuracy: 0.7291\n",
      "Epoch 6/25\n",
      "3613/3613 [==============================] - 1s 260us/sample - loss: 0.2839 - accuracy: 0.8981 - val_loss: 0.8334 - val_accuracy: 0.7032\n",
      "Epoch 7/25\n",
      "3613/3613 [==============================] - 1s 256us/sample - loss: 0.2382 - accuracy: 0.9153 - val_loss: 0.8941 - val_accuracy: 0.7089\n",
      "Epoch 8/25\n",
      "3613/3613 [==============================] - 1s 250us/sample - loss: 0.2042 - accuracy: 0.9316 - val_loss: 0.9128 - val_accuracy: 0.7061\n",
      "Epoch 9/25\n",
      "3613/3613 [==============================] - 1s 255us/sample - loss: 0.1790 - accuracy: 0.9422 - val_loss: 0.9437 - val_accuracy: 0.7147\n",
      "Epoch 10/25\n",
      "3613/3613 [==============================] - 1s 259us/sample - loss: 0.1460 - accuracy: 0.9527 - val_loss: 1.0074 - val_accuracy: 0.7147\n",
      "Epoch 11/25\n",
      "3613/3613 [==============================] - 1s 255us/sample - loss: 0.1301 - accuracy: 0.9596 - val_loss: 1.0451 - val_accuracy: 0.7032\n",
      "Epoch 12/25\n",
      "3613/3613 [==============================] - 1s 257us/sample - loss: 0.1198 - accuracy: 0.9651 - val_loss: 1.0722 - val_accuracy: 0.7118\n",
      "Epoch 13/25\n",
      "3613/3613 [==============================] - 1s 259us/sample - loss: 0.1133 - accuracy: 0.9682 - val_loss: 1.1235 - val_accuracy: 0.7176\n",
      "Epoch 14/25\n",
      "3613/3613 [==============================] - 1s 255us/sample - loss: 0.1001 - accuracy: 0.9709 - val_loss: 1.1569 - val_accuracy: 0.7061\n",
      "Epoch 15/25\n",
      "3613/3613 [==============================] - 1s 353us/sample - loss: 0.0970 - accuracy: 0.9693 - val_loss: 1.1774 - val_accuracy: 0.7003\n",
      "Epoch 16/25\n",
      "3613/3613 [==============================] - 1s 275us/sample - loss: 0.0913 - accuracy: 0.9732 - val_loss: 1.2448 - val_accuracy: 0.6945\n",
      "Epoch 17/25\n",
      "3613/3613 [==============================] - 1s 288us/sample - loss: 0.0910 - accuracy: 0.9729 - val_loss: 1.2313 - val_accuracy: 0.7147\n",
      "Epoch 18/25\n",
      "3613/3613 [==============================] - 1s 250us/sample - loss: 0.0804 - accuracy: 0.9743 - val_loss: 1.2619 - val_accuracy: 0.7003\n",
      "Epoch 19/25\n",
      "3613/3613 [==============================] - 1s 270us/sample - loss: 0.0816 - accuracy: 0.9729 - val_loss: 1.2663 - val_accuracy: 0.6888\n",
      "Epoch 20/25\n",
      "3613/3613 [==============================] - 1s 270us/sample - loss: 0.0775 - accuracy: 0.9762 - val_loss: 1.3369 - val_accuracy: 0.6801\n",
      "Epoch 21/25\n",
      "3613/3613 [==============================] - 1s 254us/sample - loss: 0.0741 - accuracy: 0.9748 - val_loss: 1.3213 - val_accuracy: 0.6916\n",
      "Epoch 22/25\n",
      "3613/3613 [==============================] - 1s 271us/sample - loss: 0.0715 - accuracy: 0.9765 - val_loss: 1.3408 - val_accuracy: 0.6744\n",
      "Epoch 23/25\n",
      "3613/3613 [==============================] - 1s 337us/sample - loss: 0.0663 - accuracy: 0.9765 - val_loss: 1.3482 - val_accuracy: 0.6916\n",
      "Epoch 24/25\n",
      "3613/3613 [==============================] - 1s 286us/sample - loss: 0.0638 - accuracy: 0.9770 - val_loss: 1.3986 - val_accuracy: 0.6801\n",
      "Epoch 25/25\n",
      "3613/3613 [==============================] - 1s 273us/sample - loss: 0.0635 - accuracy: 0.9756 - val_loss: 1.4750 - val_accuracy: 0.6744\n",
      "training finish\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('logs/training_log.csv')\n",
    "\n",
    "# training setting\n",
    "epochs = 25\n",
    "batch_size = 32\n",
    "\n",
    "# convert to array to circumvent data adapter error?\n",
    "\n",
    "# training!\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    callbacks=[csv_logger],\n",
    "                    validation_data = (X_test, y_test))\n",
    "print('training finish')\n",
    "\n",
    "# sometimes model plateaus\n",
    "# accuracy low at the start then increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-27f4ff29795c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcsv_logger\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                     validation_data = (X_test2, y_test2))\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training finish'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         validation_split=validation_split)\n\u001b[0m\u001b[1;32m    207\u001b[0m     dist_utils.validate_callbacks(input_callbacks=callbacks,\n\u001b[1;32m    208\u001b[0m                                   optimizer=model.optimizer)\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py\u001b[0m in \u001b[0;36mprocess_batch_and_step_size\u001b[0;34m(strategy, inputs, batch_size, steps_per_epoch, mode, validation_split)\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[0mfirst_x_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_x_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_x_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m       \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('logs/training_log.csv')\n",
    "\n",
    "# training setting\n",
    "epochs = 25\n",
    "batch_size = 32\n",
    "\n",
    "# convert to array to circumvent data adapter error?\n",
    "X_train2 = np.asarray(X_train)\n",
    "y_train2 = np.asarray(y_train)\n",
    "X_test2 = np.asarray(X_test)\n",
    "y_test2 = np.asarray(y_test)\n",
    "\n",
    "# training!\n",
    "history = model.fit(X_train2, y_train2, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    callbacks=[csv_logger],\n",
    "                    validation_data = (X_test2, y_test2))\n",
    "print('training finish')\n",
    "\n",
    "# sometimes model plateaus\n",
    "# accuracy low at the start then increases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Predict on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.2080367e-07, 2.3009109e-06, 9.9999714e-01, 3.4069885e-08],\n",
       "       [1.4004179e-06, 9.9989963e-01, 3.6007143e-06, 9.5314761e-05],\n",
       "       [6.0257655e-01, 7.1058876e-06, 3.5728313e-04, 3.9705911e-01],\n",
       "       [5.4840206e-07, 1.6855090e-06, 9.9999702e-01, 6.5068804e-07],\n",
       "       [9.9832767e-01, 2.5666045e-04, 9.8139537e-04, 4.3436064e-04]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict\n",
    "pred_result = model.predict(X_test, batch_size=128)\n",
    "pred_result[:5]\n",
    "\n",
    "# first line in array -> is the prediction (so joy in this exmaple), second fear etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy', 'fear', 'anger', 'joy', 'anger'], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result = label_decode(label_encoder, pred_result)\n",
    "pred_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('testing accuracy: {}'.format(round(accuracy_score(label_decode(label_encoder, y_test), pred_result), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365624</td>\n",
       "      <td>1.317255</td>\n",
       "      <td>0.463977</td>\n",
       "      <td>1.248742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.657348</td>\n",
       "      <td>0.962972</td>\n",
       "      <td>0.680115</td>\n",
       "      <td>0.893465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.795184</td>\n",
       "      <td>0.568741</td>\n",
       "      <td>0.706052</td>\n",
       "      <td>0.744871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.840299</td>\n",
       "      <td>0.423966</td>\n",
       "      <td>0.723343</td>\n",
       "      <td>0.737584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.870468</td>\n",
       "      <td>0.342428</td>\n",
       "      <td>0.729107</td>\n",
       "      <td>0.810539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.898146</td>\n",
       "      <td>0.283942</td>\n",
       "      <td>0.703170</td>\n",
       "      <td>0.833352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.915306</td>\n",
       "      <td>0.238184</td>\n",
       "      <td>0.708934</td>\n",
       "      <td>0.894067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.931636</td>\n",
       "      <td>0.204179</td>\n",
       "      <td>0.706052</td>\n",
       "      <td>0.912785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.942153</td>\n",
       "      <td>0.178985</td>\n",
       "      <td>0.714697</td>\n",
       "      <td>0.943728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.952671</td>\n",
       "      <td>0.145974</td>\n",
       "      <td>0.714697</td>\n",
       "      <td>1.007383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.959590</td>\n",
       "      <td>0.130121</td>\n",
       "      <td>0.703170</td>\n",
       "      <td>1.045075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.965126</td>\n",
       "      <td>0.119828</td>\n",
       "      <td>0.711816</td>\n",
       "      <td>1.072210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.968171</td>\n",
       "      <td>0.113344</td>\n",
       "      <td>0.717579</td>\n",
       "      <td>1.123545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.970938</td>\n",
       "      <td>0.100106</td>\n",
       "      <td>0.706052</td>\n",
       "      <td>1.156892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.969278</td>\n",
       "      <td>0.096955</td>\n",
       "      <td>0.700288</td>\n",
       "      <td>1.177449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.973152</td>\n",
       "      <td>0.091313</td>\n",
       "      <td>0.694524</td>\n",
       "      <td>1.244802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.972876</td>\n",
       "      <td>0.090989</td>\n",
       "      <td>0.714697</td>\n",
       "      <td>1.231344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.974260</td>\n",
       "      <td>0.080362</td>\n",
       "      <td>0.700288</td>\n",
       "      <td>1.261929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.972876</td>\n",
       "      <td>0.081562</td>\n",
       "      <td>0.688761</td>\n",
       "      <td>1.266341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0.976197</td>\n",
       "      <td>0.077500</td>\n",
       "      <td>0.680115</td>\n",
       "      <td>1.336856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.974813</td>\n",
       "      <td>0.074087</td>\n",
       "      <td>0.691643</td>\n",
       "      <td>1.321270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0.976474</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.674352</td>\n",
       "      <td>1.340830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0.976474</td>\n",
       "      <td>0.066343</td>\n",
       "      <td>0.691643</td>\n",
       "      <td>1.348195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>0.977027</td>\n",
       "      <td>0.063836</td>\n",
       "      <td>0.680115</td>\n",
       "      <td>1.398601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0.975643</td>\n",
       "      <td>0.063526</td>\n",
       "      <td>0.674352</td>\n",
       "      <td>1.474986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  accuracy      loss  val_accuracy  val_loss\n",
       "0       0  0.365624  1.317255      0.463977  1.248742\n",
       "1       1  0.657348  0.962972      0.680115  0.893465\n",
       "2       2  0.795184  0.568741      0.706052  0.744871\n",
       "3       3  0.840299  0.423966      0.723343  0.737584\n",
       "4       4  0.870468  0.342428      0.729107  0.810539\n",
       "5       5  0.898146  0.283942      0.703170  0.833352\n",
       "6       6  0.915306  0.238184      0.708934  0.894067\n",
       "7       7  0.931636  0.204179      0.706052  0.912785\n",
       "8       8  0.942153  0.178985      0.714697  0.943728\n",
       "9       9  0.952671  0.145974      0.714697  1.007383\n",
       "10     10  0.959590  0.130121      0.703170  1.045075\n",
       "11     11  0.965126  0.119828      0.711816  1.072210\n",
       "12     12  0.968171  0.113344      0.717579  1.123545\n",
       "13     13  0.970938  0.100106      0.706052  1.156892\n",
       "14     14  0.969278  0.096955      0.700288  1.177449\n",
       "15     15  0.973152  0.091313      0.694524  1.244802\n",
       "16     16  0.972876  0.090989      0.714697  1.231344\n",
       "17     17  0.974260  0.080362      0.700288  1.261929\n",
       "18     18  0.972876  0.081562      0.688761  1.266341\n",
       "19     19  0.976197  0.077500      0.680115  1.336856\n",
       "20     20  0.974813  0.074087      0.691643  1.321270\n",
       "21     21  0.976474  0.071460      0.674352  1.340830\n",
       "22     22  0.976474  0.066343      0.691643  1.348195\n",
       "23     23  0.977027  0.063836      0.680115  1.398601\n",
       "24     24  0.975643  0.063526      0.674352  1.474986"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's take a look at the training log\n",
    "training_log = pd.DataFrame()\n",
    "training_log = pd.read_csv(\"logs/training_log.csv\")\n",
    "training_log\n",
    "\n",
    "# training accuxracy is high, loss is low, but validation plateaus at 67% :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 6 (Take home): **  \n",
    "\n",
    "Plot the Training and Validation Accuracy and Loss (different plots), just like the images below (Note: the pictures below are an example from a different model). How to interpret the graphs you got? How are they related to the concept of overfitting/underfitting covered in class?\n",
    "<table><tr>\n",
    "    <td><img src=\"pics/pic3.png\" style=\"width: 300px;\"/> </td>\n",
    "    <td><img src=\"pics/pic4.png\" style=\"width: 300px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "If you don't have a GPU (level is higher than GTX 1060) or you are not good at setting lots of things about computer, we recommend you to use the [kaggle kernel](https://www.kaggle.com/kernels) to do deep learning model training. They have already installed all the librarys and provided free GPU for you to use.\n",
    "\n",
    "Note however that you will only be able to run a kernel for 6 hours. After 6 hours of inactivity, your Kaggle kernel will shut down (meaning if your model takes more than 6 hours to train, you can't train it at once).\n",
    "\n",
    "\n",
    "### More Information for your reference\n",
    "\n",
    "* Keras document: https://keras.io/\n",
    "* Keras GitHub example: https://github.com/keras-team/keras/tree/master/examples\n",
    "* CS229: Machine Learning: http://cs229.stanford.edu/syllabus.html\n",
    "* Deep Learning cheatsheet: https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-deep-learning\n",
    "* If you want to try TensorFlow or PyTorch: https://pytorch.org/tutorials/\n",
    "https://www.tensorflow.org/tutorials/quickstart/beginner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Word2Vector\n",
    "\n",
    "We will introduce how to use `gensim` to train your word2vec model and how to load a pre-trained model.\n",
    "\n",
    "https://radimrehurek.com/gensim/index.html\n",
    "\n",
    "Word2Vec preserves more context - if graphed, men and boy will be closer together, woman and girl closer together, the two groups will also be semantically farther apart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Prepare training corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>487</td>\n",
       "      <td>10487</td>\n",
       "      <td>Like I can't do 12 hours worth of standing or ...</td>\n",
       "      <td>[Like, I, ca, n't, do, 12, hours, worth, of, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2356</td>\n",
       "      <td>30352</td>\n",
       "      <td>15 minutes of yoga to your breakfast routine w...</td>\n",
       "      <td>[15, minutes, of, yoga, to, your, breakfast, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1164</td>\n",
       "      <td>20307</td>\n",
       "      <td>How I Murdered Your Mother #SpookyTv #horror</td>\n",
       "      <td>[How, I, Murdered, Your, Mother, #, SpookyTv, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>20543</td>\n",
       "      <td>That last minute was like watching a horror sh...</td>\n",
       "      <td>[That, last, minute, was, like, watching, a, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2277</td>\n",
       "      <td>30273</td>\n",
       "      <td>Watching Avatar and wondering why I took so lo...</td>\n",
       "      <td>[Watching, Avatar, and, wondering, why, I, too...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  \\\n",
       "487   10487  Like I can't do 12 hours worth of standing or ...   \n",
       "2356  30352  15 minutes of yoga to your breakfast routine w...   \n",
       "1164  20307       How I Murdered Your Mother #SpookyTv #horror   \n",
       "1400  20543  That last minute was like watching a horror sh...   \n",
       "2277  30273  Watching Avatar and wondering why I took so lo...   \n",
       "\n",
       "                                         text_tokenized  \n",
       "487   [Like, I, ca, n't, do, 12, hours, worth, of, s...  \n",
       "2356  [15, minutes, of, yoga, to, your, breakfast, r...  \n",
       "1164  [How, I, Murdered, Your, Mother, #, SpookyTv, ...  \n",
       "1400  [That, last, minute, was, like, watching, a, h...  \n",
       "2277  [Watching, Avatar, and, wondering, why, I, too...  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check library\n",
    "import gensim\n",
    "\n",
    "## ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# # if you want to see the training messages, you can use it\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "## the input type\n",
    "train_df['text_tokenized'] = train_df['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "train_df[['id', 'text', 'text_tokenized']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['Like', 'I', 'ca', \"n't\", 'do', '12', 'hours', 'worth', 'of', 'standing', 'or', 'calorie', 'burning', 'in', '3', 'hours', '😭😭😭😭', '#', '1stworldprobs4vs']),\n",
       "       list(['15', 'minutes', 'of', 'yoga', 'to', 'your', 'breakfast', 'routine', 'will', 'change', 'your', 'day', '#', 'preparation', '#', 'sunriseyoga', '#', 'bodyawareness', '#', 'health', '#', 'yoga', '#', 'stretch']),\n",
       "       list(['How', 'I', 'Murdered', 'Your', 'Mother', '#', 'SpookyTv', '#', 'horror'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the training corpus\n",
    "training_corpus = train_df['text_tokenized'].values\n",
    "training_corpus[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Training our model\n",
    "\n",
    "You can try to train your own model. More details: https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>487</td>\n",
       "      <td>10487</td>\n",
       "      <td>Like I can't do 12 hours worth of standing or ...</td>\n",
       "      <td>[Like, I, ca, n't, do, 12, hours, worth, of, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2356</td>\n",
       "      <td>30352</td>\n",
       "      <td>15 minutes of yoga to your breakfast routine w...</td>\n",
       "      <td>[15, minutes, of, yoga, to, your, breakfast, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1164</td>\n",
       "      <td>20307</td>\n",
       "      <td>How I Murdered Your Mother #SpookyTv #horror</td>\n",
       "      <td>[How, I, Murdered, Your, Mother, #, SpookyTv, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>20543</td>\n",
       "      <td>That last minute was like watching a horror sh...</td>\n",
       "      <td>[That, last, minute, was, like, watching, a, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2277</td>\n",
       "      <td>30273</td>\n",
       "      <td>Watching Avatar and wondering why I took so lo...</td>\n",
       "      <td>[Watching, Avatar, and, wondering, why, I, too...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  \\\n",
       "487   10487  Like I can't do 12 hours worth of standing or ...   \n",
       "2356  30352  15 minutes of yoga to your breakfast routine w...   \n",
       "1164  20307       How I Murdered Your Mother #SpookyTv #horror   \n",
       "1400  20543  That last minute was like watching a horror sh...   \n",
       "2277  30273  Watching Avatar and wondering why I took so lo...   \n",
       "\n",
       "                                         text_tokenized  \n",
       "487   [Like, I, ca, n't, do, 12, hours, worth, of, s...  \n",
       "2356  [15, minutes, of, yoga, to, your, breakfast, r...  \n",
       "1164  [How, I, Murdered, Your, Mother, #, SpookyTv, ...  \n",
       "1400  [That, last, minute, was, like, watching, a, h...  \n",
       "2277  [Watching, Avatar, and, wondering, why, I, too...  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the input type\n",
    "train_df['text_tokenized'] = train_df['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "train_df[['id', 'text', 'text_tokenized']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "## setting\n",
    "\n",
    "# vector_dim = how many dimensions we want our word embeddings to be represented by? creates vector of 100 dimensions that represent one word and can be plotted in vector space\n",
    "vector_dim = 100\n",
    "\n",
    "window_size = 5\n",
    "min_count = 1\n",
    "training_iter = 20\n",
    "\n",
    "## model\n",
    "# WORD2VEC NEEDS SENTENCES TO BE TRAINED, BECAUSE WORD2VEC USES CONTEXT\n",
    "word2vec_model = Word2Vec(sentences=training_corpus, \n",
    "                          size=vector_dim, window=window_size, \n",
    "                          min_count=min_count, iter=training_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imgur](https://i.imgur.com/Fca3MCs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Generating word vector (embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.13090377, -0.01220139,  0.61528265, -0.08693162,  0.76180047,\n",
       "        0.67367613, -0.6590828 ,  0.85313773,  0.28727093, -0.78615314,\n",
       "        0.03855506, -0.0514872 , -0.2311154 ,  0.9605259 , -0.21231811,\n",
       "       -0.19971326, -0.5804847 ,  0.03540478, -0.29551518, -0.4742287 ,\n",
       "        0.40790418,  0.09126767, -0.08907262,  0.53945863, -0.46257326,\n",
       "        0.24516189, -0.87512153, -0.11164397, -0.88184875,  0.69409615,\n",
       "       -0.26098755,  0.43608698,  0.00360806, -0.422662  ,  0.37082833,\n",
       "        0.26350245,  0.65617377, -0.5135105 , -0.18586491, -0.24680425,\n",
       "        0.35753673, -0.09669847,  0.3276639 ,  1.0586203 ,  0.45810008,\n",
       "       -0.5252461 ,  0.07633078, -0.58585095, -0.9211173 ,  0.33680937,\n",
       "       -0.6584122 ,  0.41250098,  0.08572441,  0.299786  , -0.33148503,\n",
       "       -0.12633744,  0.22982755, -0.6405772 ,  0.7293847 , -0.9534782 ,\n",
       "        0.11352818,  1.0091134 ,  0.4795264 , -0.4214857 , -0.11398863,\n",
       "        1.2422355 , -0.7076742 ,  0.36522543,  0.27852046, -0.08065936,\n",
       "        1.2108599 , -0.11301653,  0.11428385, -0.2553662 ,  0.21802127,\n",
       "        0.03928958,  0.5204718 ,  0.24819641, -0.7655689 , -0.79214084,\n",
       "        0.44282943,  0.34951726,  0.78451383, -0.04949253,  0.02843836,\n",
       "       -0.06113792, -1.0558659 , -0.36622632,  0.5892029 , -0.45729458,\n",
       "       -0.522639  , -0.35493323,  0.02964169,  0.24680576,  0.60083085,\n",
       "        0.41920516, -0.22890046, -0.3197668 ,  0.18560052, -0.0236941 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the corresponding vector of a word\n",
    "word_vec = word2vec_model.wv['happy']\n",
    "word_vec\n",
    "\n",
    "#happy is represented by 100 feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('blessed', 0.9572749137878418),\n",
       " ('Be', 0.951248049736023),\n",
       " ('birthday', 0.9415104389190674),\n",
       " ('cant', 0.9405136108398438),\n",
       " ('help', 0.9387586116790771),\n",
       " ('🕋', 0.9347123503684998),\n",
       " ('tones', 0.9341980218887329),\n",
       " ('soldier', 0.9328030347824097),\n",
       " ('kinda', 0.9316990375518799),\n",
       " ('successful', 0.9311004281044006)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the most similar words\n",
    "word = 'happy'\n",
    "topn = 10\n",
    "word2vec_model.most_similar(word, topn=topn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Using a pre-trained w2v model\n",
    "\n",
    "Instead of training your own model ,you can use a model that has already been trained. Here, we see 2 ways of doing that:\n",
    "\n",
    "\n",
    "#### (1) Download model by yourself\n",
    "\n",
    "source: [GoogleNews-vectors-negative300](https://code.google.com/archive/p/word2vec/)\n",
    "\n",
    "more details: https://radimrehurek.com/gensim/models/keyedvectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ok\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('glad', 0.7408890724182129),\n",
       " ('pleased', 0.6632170677185059),\n",
       " ('ecstatic', 0.6626912355422974),\n",
       " ('overjoyed', 0.6599286794662476),\n",
       " ('thrilled', 0.6514049768447876),\n",
       " ('satisfied', 0.6437948942184448),\n",
       " ('proud', 0.636042058467865),\n",
       " ('delighted', 0.6272379159927368),\n",
       " ('disappointed', 0.6269949674606323),\n",
       " ('excited', 0.6247665882110596)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "## Note: this model is very huge, this will take some time ...\n",
    "# 10 mins\n",
    "model_path = \"GoogleNews/GoogleNews-vectors-negative300.bin.gz\"\n",
    "w2v_google_model = KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "print('load ok')\n",
    "\n",
    "w2v_google_model.most_similar('happy', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Using gensim api\n",
    "\n",
    "Other pretrained models are available here: https://github.com/RaRe-Technologies/gensim-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============================================-----] 91.3% 95.7/104.8MB downloaded\n",
      "load ok\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('birthday', 0.9577817916870117),\n",
       " ('thank', 0.9376667141914368),\n",
       " ('welcome', 0.93361496925354),\n",
       " ('love', 0.9176183938980103),\n",
       " ('miss', 0.916450023651123),\n",
       " ('hello', 0.9158351421356201),\n",
       " ('thanks', 0.9150084853172302),\n",
       " ('merry', 0.9053248167037964),\n",
       " ('bless', 0.902732253074646),\n",
       " ('wish', 0.9013164639472961)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "## If you see `SSL: CERTIFICATE_VERIFY_FAILED` error, use this:\n",
    "import ssl\n",
    "import urllib.request\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# twitter model - different models reflect word relationships in different ways\n",
    "# glove procures words, word2vec more synonyms\n",
    "glove_twitter_25_model = api.load(\"glove-twitter-25\")\n",
    "print('load ok')\n",
    "\n",
    "glove_twitter_25_model.most_similar('happy', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 king + woman - man = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because vector space, we can run operations on these \"word\" vectors.\n",
    "\n",
    "Let's run one of the most famous examples for Word2Vec and compute the similarity between these 3 words:\n",
    "\n",
    "Below: add king and woman but subtract man = queen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192911148071),\n",
       " ('monarch', 0.6189674139022827),\n",
       " ('princess', 0.5902431607246399),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321243286133),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.5181134343147278),\n",
       " ('sultan', 0.5098593235015869),\n",
       " ('monarchy', 0.5087411999702454)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_google_model.most_similar(positive=['king', 'woman'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 7 (Take home): **  \n",
    "\n",
    "Now, we have the word vectors, but our input data is a sequence of words (or say sentence). \n",
    "How can we utilize these \"word\" vectors to represent the sentence data and train our model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "# after we create our model, everything is according to words. but data is based on sentences. but how can we use word based vectors to represent sentences?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Clustering: k-means\n",
    "\n",
    "Here we introduce how to use `sklearn` to do the basic **unsupervised learning** approach, k-means.    \n",
    "\n",
    "more details: http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic concept\n",
    "\n",
    "![Image](https://i.imgur.com/PEdUf54.png)\n",
    "\n",
    "(img source: https://towardsdatascience.com/k-means-clustering-identifying-f-r-i-e-n-d-s-in-the-world-of-strangers-695537505d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target words:  ['happy', 'fear', 'angry', 'car', 'teacher', 'computer']\n"
     ]
    }
   ],
   "source": [
    "# clustering target\n",
    "target_list = ['happy', 'fear', 'angry', 'car', 'teacher', 'computer']\n",
    "print('target words: ', target_list)\n",
    "\n",
    "# convert to word vector\n",
    "X = [word2vec_model.wv[word] for word in target_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: happy \t cluster: 0\n",
      "word: fear \t cluster: 0\n",
      "word: angry \t cluster: 0\n",
      "word: car \t cluster: 1\n",
      "word: teacher \t cluster: 1\n",
      "word: computer \t cluster: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# we have to decide how many cluster (k) we want\n",
    "k = 2\n",
    "\n",
    "# k-means model\n",
    "kmeans_model = KMeans(n_clusters=k)\n",
    "kmeans_model.fit(X)\n",
    "# fit X: target word vectors into KMeans Model\n",
    "\n",
    "# cluster result\n",
    "cluster_result = kmeans_model.labels_\n",
    "\n",
    "# show\n",
    "for i in range(len(target_list)):\n",
    "    print('word: {} \\t cluster: {}'.format(target_list[i], cluster_result[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imgur](pics/pic6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check cluster membership\n",
    "word = 'student'\n",
    "word_vec = word2vec_model.wv[word]\n",
    "kmeans_model.predict([word_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check cluster membership\n",
    "word = 'sad'\n",
    "word_vec = word2vec_model.wv[word]\n",
    "kmeans_model.predict([word_vec])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 9. High-dimension Visualization: t-SNE\n",
    "\n",
    "No matter if you use the Bag-of-words, tf-idf, or word2vec, it's very hard to see the embedding result, because the dimension is larger than 3.  \n",
    "\n",
    "In Lab 1, we already talked about PCA. We can use PCA to reduce the dimension of our data, then visualize it. However, if you dig deeper into the result, you'd find it is insufficient...\n",
    "\n",
    "Our aim will be to create a visualization similar to the one below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](pics/pic7.png)\n",
    "source: https://www.fabian-keller.de/research/high-dimensional-data-visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we would like to introduce another visualization method called t-SNE.  \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Prepare visualizing target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare data lists like:\n",
    "    - happpy words\n",
    "    - angry words\n",
    "    - data words\n",
    "    - mining words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy_words:  ['happy', 'glad', 'pleased', 'ecstatic', 'overjoyed', 'thrilled']\n",
      "angry_words:  ['angry', 'irate', 'enraged', 'indignant', 'incensed', 'annoyed']\n",
      "data_words:  ['data', 'Data', 'datasets', 'dataset', 'databases', 'statistics']\n",
      "mining_words:  ['mining', 'Mining', 'mines', 'coal_mining', 'mine', 'miner']\n",
      "\n",
      "target words: \n",
      "['happy', 'glad', 'pleased', 'ecstatic', 'overjoyed', 'thrilled', 'angry', 'irate', 'enraged', 'indignant', 'incensed', 'annoyed', 'data', 'Data', 'datasets', 'dataset', 'databases', 'statistics', 'mining', 'Mining', 'mines', 'coal_mining', 'mine', 'miner']\n",
      "\n",
      "color list:\n",
      "['b', 'b', 'b', 'b', 'b', 'b', 'g', 'g', 'g', 'g', 'g', 'g', 'r', 'r', 'r', 'r', 'r', 'r', 'y', 'y', 'y', 'y', 'y', 'y']\n"
     ]
    }
   ],
   "source": [
    "word_list = ['happy', 'angry', 'data', 'mining']\n",
    "\n",
    "topn = 5\n",
    "happy_words = ['happy'] + [word_ for word_, sim_ in w2v_google_model.most_similar('happy', topn=topn)]\n",
    "angry_words = ['angry'] + [word_ for word_, sim_ in w2v_google_model.most_similar('angry', topn=topn)]        \n",
    "data_words = ['data'] + [word_ for word_, sim_ in w2v_google_model.most_similar('data', topn=topn)]        \n",
    "mining_words = ['mining'] + [word_ for word_, sim_ in w2v_google_model.most_similar('mining', topn=topn)]        \n",
    "\n",
    "print('happy_words: ', happy_words)\n",
    "print('angry_words: ', angry_words)\n",
    "print('data_words: ', data_words)\n",
    "print('mining_words: ', mining_words)\n",
    "\n",
    "target_words = happy_words + angry_words + data_words + mining_words\n",
    "print('\\ntarget words: ')\n",
    "print(target_words)\n",
    "\n",
    "print('\\ncolor list:')\n",
    "cn = topn + 1\n",
    "color = ['b'] * cn + ['g'] * cn + ['r'] * cn + ['y'] * cn\n",
    "print(color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Plot using t-SNE (2-dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 862.5x862.5 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "## w2v model\n",
    "model = w2v_google_model\n",
    "\n",
    "## prepare training word vectors\n",
    "size = 200\n",
    "target_size = len(target_words)\n",
    "all_word = list(model.vocab.keys())\n",
    "word_train = target_words + all_word[:size]\n",
    "X_train = model[word_train]\n",
    "\n",
    "## t-SNE model\n",
    "tsne = TSNE(n_components=2, metric='cosine', random_state=28)\n",
    "\n",
    "## training\n",
    "X_tsne = tsne.fit_transform(X_train)\n",
    "\n",
    "## plot the result\n",
    "plt.figure(figsize=(7.5, 7.5), dpi=115)\n",
    "plt.scatter(X_tsne[:target_size, 0], X_tsne[:target_size, 1], c=color)\n",
    "for label, x, y in zip(target_words, X_tsne[:target_size, 0], X_tsne[:target_size, 1]):\n",
    "    plt.annotate(label, xy=(x,y), xytext=(0,0),  textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 8 (Take home): **  \n",
    "\n",
    "Generate a t-SNE visualization to show the 15 words most related to the words \"angry\", \"happy\", \"sad\", \"fear\" (60 words total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Elmo embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides Word2Vec, several other pretrained models for generating embeddings exist. Here, we'll take a look at ElMo embeddings.\n",
    "Elmo is a language model trained on a task to predict the next word in a sequence of words, but is bidirectional (unlike word2vec).\n",
    "\n",
    "[Image](pic/pics8.png)\n",
    "\n",
    "Source: (http://jalammar.github.io/illustrated-bert/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To embed the sentences, we need to tokenize them and get them into a tensor of uniform shape.This means every sentence should have the same amount of tokens  (ie. If we have 5 sentences, we should have an array of 5 * x ). We will achieve this through padding, or adding \"\" at the end of each sentence for each missing token up to x.\n",
    "\n",
    "We'll be using the Keras tokenizer to tokenize and pad. Keras tokenizer will first map each word to a number, and we'll get the tokenizing below in the text_tok_keras column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_tok_keras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>487</td>\n",
       "      <td>10487</td>\n",
       "      <td>Like I can't do 12 hours worth of standing or ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "      <td>[Like, I, ca, n't, do, 12, hours, worth, of, s...</td>\n",
       "      <td>[27, 3, 75, 50, 480, 517, 917, 6, 2509, 51, 49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2356</td>\n",
       "      <td>30352</td>\n",
       "      <td>15 minutes of yoga to your breakfast routine w...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.521</td>\n",
       "      <td>[15, minutes, of, yoga, to, your, breakfast, r...</td>\n",
       "      <td>[420, 686, 6, 1424, 2, 30, 1425, 2510, 48, 446...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1164</td>\n",
       "      <td>20307</td>\n",
       "      <td>How I Murdered Your Mother #SpookyTv #horror</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.625</td>\n",
       "      <td>[How, I, Murdered, Your, Mother, #, SpookyTv, ...</td>\n",
       "      <td>[54, 3, 2513, 30, 918, 2514, 159]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>20543</td>\n",
       "      <td>That last minute was like watching a horror sh...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[That, last, minute, was, like, watching, a, h...</td>\n",
       "      <td>[11, 181, 2515, 29, 27, 253, 4, 159, 329, 208,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2277</td>\n",
       "      <td>30273</td>\n",
       "      <td>Watching Avatar and wondering why I took so lo...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.580</td>\n",
       "      <td>[Watching, Avatar, and, wondering, why, I, too...</td>\n",
       "      <td>[253, 4994, 5, 1814, 78, 3, 518, 18, 223, 2, 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text emotion  \\\n",
       "487   10487  Like I can't do 12 hours worth of standing or ...   anger   \n",
       "2356  30352  15 minutes of yoga to your breakfast routine w...     joy   \n",
       "1164  20307       How I Murdered Your Mother #SpookyTv #horror    fear   \n",
       "1400  20543  That last minute was like watching a horror sh...    fear   \n",
       "2277  30273  Watching Avatar and wondering why I took so lo...     joy   \n",
       "\n",
       "      intensity                                     text_tokenized  \\\n",
       "487       0.458  [Like, I, ca, n't, do, 12, hours, worth, of, s...   \n",
       "2356      0.521  [15, minutes, of, yoga, to, your, breakfast, r...   \n",
       "1164      0.625  [How, I, Murdered, Your, Mother, #, SpookyTv, ...   \n",
       "1400      0.500  [That, last, minute, was, like, watching, a, h...   \n",
       "2277      0.580  [Watching, Avatar, and, wondering, why, I, too...   \n",
       "\n",
       "                                         text_tok_keras  \n",
       "487   [27, 3, 75, 50, 480, 517, 917, 6, 2509, 51, 49...  \n",
       "2356  [420, 686, 6, 1424, 2, 30, 1425, 2510, 48, 446...  \n",
       "1164                  [54, 3, 2513, 30, 918, 2514, 159]  \n",
       "1400  [11, 181, 2515, 29, 27, 253, 4, 159, 329, 208,...  \n",
       "2277  [253, 4994, 5, 1814, 78, 3, 518, 18, 223, 2, 7...  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#Initializing tokenizer, getting rid of some punctuation\n",
    "\n",
    "# will not consider symbols below in tokenization\n",
    "tokenizer_keras = Tokenizer(filters='\"#%&()*+,-./:;<=>@[\\]^`{|}~')\n",
    "\n",
    "tokenizer_keras.fit_on_texts(train_df['text'])\n",
    "train_df['text_tok_keras'] = tokenizer_keras.texts_to_sequences(train_df['text'])\n",
    "train_df.head()\n",
    "\n",
    "# keras tokens - maps each word to a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 18, 7, 11, 17]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the length of the tokenized sentences\n",
    "list(map(lambda x: len(x), train_df['text_tok_keras'].iloc[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discussed, the length of the tokenized sentences is not the same, so we pad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_tok_keras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>487</td>\n",
       "      <td>10487</td>\n",
       "      <td>Like I can't do 12 hours worth of standing or ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "      <td>[Like, I, ca, n't, do, 12, hours, worth, of, s...</td>\n",
       "      <td>[27, 3, 75, 50, 480, 517, 917, 6, 2509, 51, 49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2356</td>\n",
       "      <td>30352</td>\n",
       "      <td>15 minutes of yoga to your breakfast routine w...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.521</td>\n",
       "      <td>[15, minutes, of, yoga, to, your, breakfast, r...</td>\n",
       "      <td>[420, 686, 6, 1424, 2, 30, 1425, 2510, 48, 446...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1164</td>\n",
       "      <td>20307</td>\n",
       "      <td>How I Murdered Your Mother #SpookyTv #horror</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.625</td>\n",
       "      <td>[How, I, Murdered, Your, Mother, #, SpookyTv, ...</td>\n",
       "      <td>[54, 3, 2513, 30, 918, 2514, 159, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>20543</td>\n",
       "      <td>That last minute was like watching a horror sh...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[That, last, minute, was, like, watching, a, h...</td>\n",
       "      <td>[11, 181, 2515, 29, 27, 253, 4, 159, 329, 208,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2277</td>\n",
       "      <td>30273</td>\n",
       "      <td>Watching Avatar and wondering why I took so lo...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.580</td>\n",
       "      <td>[Watching, Avatar, and, wondering, why, I, too...</td>\n",
       "      <td>[253, 4994, 5, 1814, 78, 3, 518, 18, 223, 2, 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text emotion  \\\n",
       "487   10487  Like I can't do 12 hours worth of standing or ...   anger   \n",
       "2356  30352  15 minutes of yoga to your breakfast routine w...     joy   \n",
       "1164  20307       How I Murdered Your Mother #SpookyTv #horror    fear   \n",
       "1400  20543  That last minute was like watching a horror sh...    fear   \n",
       "2277  30273  Watching Avatar and wondering why I took so lo...     joy   \n",
       "\n",
       "      intensity                                     text_tokenized  \\\n",
       "487       0.458  [Like, I, ca, n't, do, 12, hours, worth, of, s...   \n",
       "2356      0.521  [15, minutes, of, yoga, to, your, breakfast, r...   \n",
       "1164      0.625  [How, I, Murdered, Your, Mother, #, SpookyTv, ...   \n",
       "1400      0.500  [That, last, minute, was, like, watching, a, h...   \n",
       "2277      0.580  [Watching, Avatar, and, wondering, why, I, too...   \n",
       "\n",
       "                                         text_tok_keras  \n",
       "487   [27, 3, 75, 50, 480, 517, 917, 6, 2509, 51, 49...  \n",
       "2356  [420, 686, 6, 1424, 2, 30, 1425, 2510, 48, 446...  \n",
       "1164  [54, 3, 2513, 30, 918, 2514, 159, 0, 0, 0, 0, ...  \n",
       "1400  [11, 181, 2515, 29, 27, 253, 4, 159, 329, 208,...  \n",
       "2277  [253, 4994, 5, 1814, 78, 3, 518, 18, 223, 2, 7...  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#pad sequences: max len is 30, so we want all to be 30, so we pad\n",
    "maxlen = 30 # arbitrary\n",
    "padded_tokens = pad_sequences(train_df['text_tok_keras'],  maxlen=maxlen, padding=\"post\")\n",
    "train_df['text_tok_keras'] = list(padded_tokens)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we map back to words to obtain the padded tokenized representations in the text_tok_keras_words column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_tok_keras</th>\n",
       "      <th>text_tok_keras_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>487</td>\n",
       "      <td>10487</td>\n",
       "      <td>Like I can't do 12 hours worth of standing or ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "      <td>[Like, I, ca, n't, do, 12, hours, worth, of, s...</td>\n",
       "      <td>[27, 3, 75, 50, 480, 517, 917, 6, 2509, 51, 49...</td>\n",
       "      <td>[like, i, can't, do, 12, hours, worth, of, sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2356</td>\n",
       "      <td>30352</td>\n",
       "      <td>15 minutes of yoga to your breakfast routine w...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.521</td>\n",
       "      <td>[15, minutes, of, yoga, to, your, breakfast, r...</td>\n",
       "      <td>[420, 686, 6, 1424, 2, 30, 1425, 2510, 48, 446...</td>\n",
       "      <td>[15, minutes, of, yoga, to, your, breakfast, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1164</td>\n",
       "      <td>20307</td>\n",
       "      <td>How I Murdered Your Mother #SpookyTv #horror</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.625</td>\n",
       "      <td>[How, I, Murdered, Your, Mother, #, SpookyTv, ...</td>\n",
       "      <td>[54, 3, 2513, 30, 918, 2514, 159, 0, 0, 0, 0, ...</td>\n",
       "      <td>[how, i, murdered, your, mother, spookytv, hor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>20543</td>\n",
       "      <td>That last minute was like watching a horror sh...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[That, last, minute, was, like, watching, a, h...</td>\n",
       "      <td>[11, 181, 2515, 29, 27, 253, 4, 159, 329, 208,...</td>\n",
       "      <td>[that, last, minute, was, like, watching, a, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2277</td>\n",
       "      <td>30273</td>\n",
       "      <td>Watching Avatar and wondering why I took so lo...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.580</td>\n",
       "      <td>[Watching, Avatar, and, wondering, why, I, too...</td>\n",
       "      <td>[253, 4994, 5, 1814, 78, 3, 518, 18, 223, 2, 7...</td>\n",
       "      <td>[watching, avatar, and, wondering, why, i, too...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text emotion  \\\n",
       "487   10487  Like I can't do 12 hours worth of standing or ...   anger   \n",
       "2356  30352  15 minutes of yoga to your breakfast routine w...     joy   \n",
       "1164  20307       How I Murdered Your Mother #SpookyTv #horror    fear   \n",
       "1400  20543  That last minute was like watching a horror sh...    fear   \n",
       "2277  30273  Watching Avatar and wondering why I took so lo...     joy   \n",
       "\n",
       "      intensity                                     text_tokenized  \\\n",
       "487       0.458  [Like, I, ca, n't, do, 12, hours, worth, of, s...   \n",
       "2356      0.521  [15, minutes, of, yoga, to, your, breakfast, r...   \n",
       "1164      0.625  [How, I, Murdered, Your, Mother, #, SpookyTv, ...   \n",
       "1400      0.500  [That, last, minute, was, like, watching, a, h...   \n",
       "2277      0.580  [Watching, Avatar, and, wondering, why, I, too...   \n",
       "\n",
       "                                         text_tok_keras  \\\n",
       "487   [27, 3, 75, 50, 480, 517, 917, 6, 2509, 51, 49...   \n",
       "2356  [420, 686, 6, 1424, 2, 30, 1425, 2510, 48, 446...   \n",
       "1164  [54, 3, 2513, 30, 918, 2514, 159, 0, 0, 0, 0, ...   \n",
       "1400  [11, 181, 2515, 29, 27, 253, 4, 159, 329, 208,...   \n",
       "2277  [253, 4994, 5, 1814, 78, 3, 518, 18, 223, 2, 7...   \n",
       "\n",
       "                                   text_tok_keras_words  \n",
       "487   [like, i, can't, do, 12, hours, worth, of, sta...  \n",
       "2356  [15, minutes, of, yoga, to, your, breakfast, r...  \n",
       "1164  [how, i, murdered, your, mother, spookytv, hor...  \n",
       "1400  [that, last, minute, was, like, watching, a, h...  \n",
       "2277  [watching, avatar, and, wondering, why, i, too...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map back to words\n",
    "reverse_word_map = dict(map(reversed, tokenizer_keras.word_index.items()))\n",
    "train_df['text_tok_keras_words'] = train_df['text_tok_keras'].apply(lambda x_list: [reverse_word_map[x] if x>0 else \"\" for x in x_list])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use the Tensorflow Hub to charge a pretrained Elmo model. TensorFlow Hub is a library for reusable machine learning models. You can learn more here:\n",
    "Source: (https://www.tensorflow.org/hub)\n",
    "Make sure tensor has appropriate size!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "variable_scope module_5/ was unused but the corresponding name_scope was already taken.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-d5feb75beab8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#load elmo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0melmo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://tfhub.dev/google/elmo/3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#generic way to generate an array of the same length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, spec, trainable, name, tags)\u001b[0m\n\u001b[1;32m    154\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such graph variant: tags=%r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0mabs_state_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_get_state_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmark_name_scope_used\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs_state_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36m_try_get_state_scope\u001b[0;34m(name, mark_name_scope_used)\u001b[0m\n\u001b[1;32m    387\u001b[0m       raise RuntimeError(\n\u001b[1;32m    388\u001b[0m           \u001b[0;34m\"variable_scope %s was unused but the corresponding \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m           \"name_scope was already taken.\" % abs_state_scope)\n\u001b[0m\u001b[1;32m    390\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mabs_state_scope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: variable_scope module_5/ was unused but the corresponding name_scope was already taken."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "#load elmo\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/3\", trainable = True)\n",
    "\n",
    "#generic way to generate an array of the same length\n",
    "token_len = np.empty(len(train_df))\n",
    "token_len.fill(maxlen)\n",
    "\n",
    "#create embeddings\n",
    "embeddings = elmo(inputs={\"tokens\": list(train_df['text_tok_keras_words']),\n",
    "                          \"sequence_len\": token_len},\n",
    "                  signature=\"tokens\",\n",
    "                  as_dict=True)[\"elmo\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-03e43752aada>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#check the Embedding layer dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "#check the Embedding layer dimension\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To embed a word, you need to pass the position of the token. Let's take the first sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Like I can't do 12 hours worth of standing or calorie burning in 3 hours 😭😭😭😭 #1stworldprobs4vs\""
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this might take a long time, make sure you can run Tf on your computer\n",
    "# shows representation of words in vectorspace.. will probably crash your PC though. don't try running it!!\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "print(\"SusannahSpot\")\n",
    "print(sess.run(embeddings[0][1]))\n",
    "\n",
    "print(\"I\")\n",
    "print(sess.run(embeddings[0][1]))\n",
    "\n",
    "print(\"could\")\n",
    "print(sess.run(embeddings[0][2]))\n",
    "\n",
    "print(\"pop\")\n",
    "print(sess.run(embeddings[0][3]))\n",
    "\n",
    "print(\"round\")\n",
    "print(sess.run(embeddings[0][4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 594.85,
   "position": {
    "height": "40px",
    "left": "723px",
    "right": "20px",
    "top": "80px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
